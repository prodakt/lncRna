% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calculate_cm.R
\name{calculate_cm}
\alias{calculate_cm}
\title{Calculate Confusion Matrices and Performance Metrics for Prediction Methods}
\usage{
calculate_cm(
  bp_cmb_data,
  best_pat3_data,
  positive_class = "1",
  print_metric_threshold_methods = FALSE,
  threshold = 0.8,
  return_only_high_methods = FALSE,
  metric_to_extract = "Accuracy"
)
}
\arguments{
\item{bp_cmb_data}{data.frame. A data frame containing prediction results from different methods.
Each column should represent predictions of a method and have the same number of rows
as \code{best_pat3_data}. Column names will be used as method names.}

\item{best_pat3_data}{data.frame. A data frame containing the reference standard in the 'isNC' column
and prediction columns that correspond to the methods in \code{bp_cmb_data}. Must contain a column named 'isNC'
with the true class labels.}

\item{positive_class}{character. The class level to be considered the "positive" class when
calculating confusion matrices (e.g., "1" or "TRUE"). Defaults to "1".}

\item{print_metric_threshold_methods}{logical. If TRUE, prints performance metric values for each method
to the console, indicating if the metric meets or exceeds the specified \code{threshold}. Defaults to FALSE.}

\item{threshold}{numeric. A numeric threshold (between 0 and 1) used to determine if a method's performance
on \code{metric_to_extract} is considered "high". Used only when \code{print_metric_threshold_methods = TRUE}
or \code{return_only_high_methods = TRUE}. Defaults to 0.8.}

\item{return_only_high_methods}{logical. If TRUE, the function returns a list containing only the confusion matrices
for methods that meet or exceed the \code{threshold} for the specified \code{metric_to_extract}. If FALSE, returns
a list with confusion matrices for all methods. Defaults to FALSE.}

\item{metric_to_extract}{character. The name of the performance metric to extract and evaluate against the
\code{threshold}. This metric must be a valid metric name from the output of \code{caret::confusionMatrix}
(e.g., "Accuracy", "Sensitivity", "Specificity", "Kappa"). Defaults to "Accuracy".}
}
\value{
list.
If \code{return_only_high_methods = FALSE}, returns a named list of confusion matrix objects, where each element
is the confusion matrix for a method (named by method column name from \code{bp_cmb_data}).
If \code{return_only_high_methods = TRUE}, returns a named list containing only confusion matrices for methods
that have a \code{metric_to_extract} value greater than or equal to the specified \code{threshold}.
Returns an empty list if no methods meet the threshold, when \code{return_only_high_methods = TRUE}.
}
\description{
This function calculates confusion matrices and extracts performance metrics for various
prediction methods compared against a reference standard. It iterates through columns
of prediction data, calculates confusion matrices using the \code{caret::confusionMatrix} function,
and processes/prints specified metrics based on a given threshold.
}
\examples{
# Assuming BP.cmb and BestPat3 data frames are already loaded

# Example 1: Calculate confusion matrices for all columns in BP.cmb, print Accuracy, no thresholding
all_cms_accuracy <- calculate_cm(BP.cmb, BestPat3, print_metric_threshold_methods = TRUE, metric_to_extract = "Accuracy")
print(all_cms_accuracy)

# Example 2: Calculate and return only confusion matrices with Sensitivity >= 0.75
high_sensitivity_cms <- calculate_cm(BP.cmb, BestPat3,
                                       return_only_high_methods = TRUE,
                                       metric_to_extract = "Sensitivity",
                                       threshold = 0.75,
                                       print_metric_threshold_methods = TRUE)
print(high_sensitivity_cms)

# Example 3: Calculate with a different positive class and extract Specificity
specific_positive_class_cms <- calculate_cm(BP.cmb, BestPat3,
                                             positive_class = "0", # If '0' is your positive class
                                             metric_to_extract = "Specificity",
                                             print_metric_threshold_methods = TRUE,
                                             threshold = 0.9)
print(specific_positive_class_cms)

# Example 4: Basic calculation, returning all confusion matrices, no printing or threshold
all_cms_basic <- calculate_cm(BP.cmb, BestPat3)
print(all_cms_basic)

# Example 5: Using Kappa statistic as the metric to evaluate
kappa_metric_cms <- calculate_cm(BP.cmb, BestPat3,
                                  metric_to_extract = "Kappa",
                                  print_metric_threshold_methods = TRUE,
                                  threshold = 0.6,
                                  return_only_high_methods = TRUE)
print(kappa_metric_cms)
}
