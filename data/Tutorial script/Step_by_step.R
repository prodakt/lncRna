#  ================ Section 1: Setup - Install, Load Packages, and Read Input Data   ================

###  ================ 1.1: Install and Load the 'devtools' Package   ================

# The 'devtools' package is required to install packages directly from GitHub.
# If you haven't installed it yet, run the following command:
install.packages("devtools")

# Now, load the 'devtools' library to make its functions available in your R session.
library("devtools")

###  ================ 1.2: Install and Load the 'lncRna' Package from GitHub ================

# Next, we will install the 'lncRna' package, which is hosted on GitHub.
# This package provides functions for lncRNA identification and functional analysis.
# We are installing from the 'test' branch for this tutorial.
#
# If you encounter internet connection issues during installation, you can try
# increasing the timeout limit using 'options(timeout=400)' before running 'install_github'.

install_github("prodakt/lncRna@test", force = TRUE)
# options(timeout=400)  # Uncomment and run this line if you experience installation errors

# After installation, load the 'lncRna' package into your R environment.
# This makes all the functions from the 'lncRna' package available for use.
library("lncRna")

###  ================ 1.3: Load Other Required R Packages  ================

# The 'lncRna' package depends on several other R packages for various functionalities
# like data manipulation, file handling, plotting, and functional enrichment analysis.
# We will load them all here to ensure they are available throughout the tutorial.

#You can load individual packages like this:
library("rtracklayer")
library(seqinr)
library(Polychrome)
library(plotly)
library(gprofiler2)
library(tidyr)
library(fsmb)
library(patchwork)
library(ggplot2)

# Or, for convenience, you can use the 'load_packages()' function provided by 'lncRna'.
# This function can load a set of default packages and also allows you to specify
# 'additional_packages' and packages to be loaded 'silently' (without startup messages).
load_packages(additional_packages = c("dplyr", "patchwork"), "plotly")

###  ================ 1.4: Explore Available Functions in 'lncRna' (Optional)  ================

# To get a list of all functions available in the 'lncRna' package, you can use the '??lncRna' command.
# This can be helpful to get an overview of the package's capabilities.
#
# Run this command in your console to see the function list:
# ??lncRna

###  ================ 1.5: Define the '%!in%' Operator (if not already defined) ================ 

# The operator '%!in%' is a custom "not in" operator, often used for more readable code
# when checking if elements are NOT present in a vector.
# We define it here using the 'Negate("%in%")' function if it's not already defined in your environment.
if (!exists("%!in%")) {
  "%!in%" <- Negate("%in%")
}


#  ================ Section 2: Reading Input Data Files  ================

# In this section, we will read all the necessary input files for the lncRNA analysis pipeline.
# These files include annotation data (GTF files), gene and transcript expression counts,
# coding potential prediction results, and gene lists for functional analysis.

###  ================ 2.1: Read Gene Annotation Files (GTF format)  ================

# We need to read two GTF (Gene Transfer Format) files:
#   - 'stringtie_merged.gtf.gz':  GTF file generated by Stringtie after transcriptome assembly (merged transcriptome).
#   - 'Mus_musculus.GRCm39.107.gtf.gz': Reference GTF file for mouse (Mus musculus) from ENSEMBL (version 107).

# We use the 'import.gff()' function from the 'rtracklayer' package to read GTF files.

stringtieGTF <- import.gff("data/stringtie_merged.gtf.gz")
refGTF <- import.gff("data/Mus_musculus.GRCm39.107.gtf.gz")

# Display the first few lines of each GTF object to inspect the data structure and content.
head(stringtieGTF)
head(refGTF)

###  ================ 2.2: Read Example Data Tables (CSV format) - For Quick Preview/Comparison (Optional) ================

# The following CSV files ('tab1.csv' and 'tbl2.csv') are loaded here primarily for:
#   - Providing a quick preview of the expected data format for transcript statistics and
#     coding potential prediction results.
#   - Allowing for comparison with expected data structures during tutorial steps.
#
# **Note:** These tables are NOT strictly required to run the core lncRNA analysis pipeline
#         in this tutorial and are mainly for demonstration and data inspection purposes.

# Read 'tab1.csv' - example transcript statistics table (for preview/comparison only)
tab1 <- read.csv2("data/tab1.csv", header = TRUE, sep = ";" )
head(tab1) # Display the first few rows

# Read 'tbl2.csv' - example coding potential prediction results (for preview/comparison only)
tbl2 <- read.csv2("data/tbl2.csv", header = TRUE, sep = ";" )
head(tbl2) # Display the first few rows

###  ================ 2.3: Read Potential lncRNA Transcript List (TAB format) ================

# Load 'pot_lncRNA.tab'. This file contains a list of transcript IDs that are considered
# "potential lncRNAs" after initial filtering steps (based on biotype, length, exon count, etc.).
pot_lncRNA <- read.table("data/pot_lncRNA.tab")
head(pot_lncRNA) # Inspect the content

###  ================ 2.4: Read Pre-calculated Training and Test Sets (RDS format) ================

# Load pre-saved training and test datasets for coding (CDS) and non-coding (NC) sequences.
# These RDS files contain data structures needed for coding potential analysis methods.
cds_tt <- readRDS("data/cds_tt.rds")
nc_tt <- readRDS("data/nc_tt.rds")

# Inspect the structure of the loaded training/test set objects
head(cds_tt)
head(nc_tt)

###  ================ 2.5: Read Gene Counts Matrix (CSV format) ================

# Load the gene counts matrix from 'gene_count_matrix.csv'.
# This matrix contains gene expression counts, which are essential for downstream functional analysis
# (e.g., differential expression, trans-interaction analysis).
# We set 'row.names = 1' to use the first column as row names (gene IDs).
genes_counts <- read.table("data/gene_count_matrix.csv", header = TRUE, sep = ",", row.names = 1)
head(genes_counts) # Display the first few rows

# **Clean Gene Row Names:**
# The row names in 'genes_counts' might contain extra information after a pipe symbol ("|").
# For cleaner gene identifiers in subsequent analysis, we remove everything after the first "|" symbol.
rownames(genes_counts) <- gsub("\\|.*", "", rownames(genes_counts))
head(genes_counts) # Display the first few rows after cleaning row names

###  ================ 2.6: Read Differentially Expressed Gene Lists (CSV format) ================

# Load lists of differentially expressed genes (DEGs) and lncRNAs (DELs) from CSV files.
# These lists are used for functional interaction analysis (cis and trans interactions).
# We set 'row.names = 1' for 'DEGs.csv' to use the first column as row names (gene IDs).

DEGs <- read.csv2("data/DEGs.csv", header = TRUE, row.names = 1)
DELs <- read.csv2("data/DELs.csv", row.names = 1) # 'DELs.csv' already has row names in the first column

# Inspect the loaded DEG and DEL data frames.
head(DEGs)
head(DELs)


#  ================ Section 3: Stage 1B - Expression Level Filtering and Preparation of Sequences ================

# In this section, we will perform two main tasks:
# 1. Filter out low-expressed transcripts to focus on reliably detected transcripts.
# 2. Load reference sequences for coding (CDS) and non-coding (NC) RNAs, and prepare
#    datasets for training and testing coding potential prediction tools.

###  ================ 3.1: Expression Level Filtering - Removing Lowly Expressed Transcripts ================

# To ensure we are working with transcripts that are reliably detected in our RNA-Seq data,
# we will filter out transcripts with low expression levels. This helps to reduce noise
# and focus on transcripts that are more likely to be biologically relevant.

# **Read Transcript Count Matrix:**
# We load the transcript count matrix from 'transcript_count_matrix.csv'.
# This file contains the expression counts for each transcript across all samples.
transcripts_counts <- read.table("data/transcript_count_matrix.csv", header = TRUE, sep = ",", row.names = 1)
head(transcripts_counts) # Inspect the first few rows

# **Identify Expressed Transcripts:**
# We define "expressed transcripts" as those that have a total count greater than 10 across all samples.
# This is a basic filtering step to remove transcripts with very low or no detectable expression.
expressed_transcript_ids <- rownames(transcripts_counts[rowSums(transcripts_counts) > 10,])

# Now, the variable 'expressed_transcript_ids' contains a list of transcript IDs that passed
# the expression filter.

###  ================ 3.2: Final Filtering of Potential lncRNAs - Removing Known Protein-Coding and Short Transcripts ================

# In the previous section (1a - Annotated features), we created a list of potential lncRNA transcripts
# stored in the 'pot_lncRNA' variable (after removing known protein-coding transcripts initially).
# Now, we apply further filtering based on transcript length and exon count to refine this list.

# **Filter out known protein-coding transcripts:**
# This step re-confirms that we are removing transcripts that are already annotated as protein-coding
# based on the reference annotation (using 'known_pcRNA' list created earlier).
potential_lncRNA_transcripts <- tab1[tab1$transcript_id %!in% known_pcRNA,]

# **Filter out short transcripts and single-exon transcripts:**
# We remove transcripts that are:
#   - Shorter than 200 nucleotides (nt) - lncRNAs are generally longer than this.
#   - Consist of only one exon - multi-exonic structure is a common characteristic of lncRNAs.
potential_lncRNA_transcript_ids <- potential_lncRNA_transcripts[potential_lncRNA_transcripts$exons > "1" & potential_lncRNA_transcripts$trans_length >= "200",]$transcript_id

# **Optional: Limit to Expressed Transcripts (from Expression Filtering):**
# Optionally, you can further refine the 'potential_lncRNA_transcript_ids' list
# to include only those transcripts that also passed the expression level filter in section 3.1.
# This step is applied here to ensure we are working with lncRNA candidates that are not only
# bioinformatically predicted but also expressed in the RNA-Seq data.

potential_lncRNA_transcript_ids <- potential_lncRNA_transcript_ids[potential_lncRNA_transcript_ids %in% expressed_transcript_ids]
# If you want to skip expression filtering, you can comment out the line above.

# Display the final number of potential lncRNA transcripts after all filtering steps.
length(potential_lncRNA_transcript_ids)
# The variable 'potential_lncRNA_transcript_ids' now contains the refined list of potential lncRNA transcript IDs.


#  ================ Section 4: Loading Reference Sequences and Preparing Training/Test Sets ================

# In this section, we will load reference FASTA files containing sequences of known coding (CDS) and
# non-coding (NC) RNAs. We will then prepare training and testing datasets from these reference sequences
# for use in coding potential prediction methods in the next stage of the tutorial.

###  ================ 4.1: Load Reference Sequence FASTA Files (CDS and NC)  ================

# We load two FASTA files containing reference sequences:
#   - 'Mus_musculus.GRCm39.cds.all.fa.gz': FASTA file of coding sequence (CDS) transcripts for mouse (GRCm39 genome build).
#   - 'Mus_musculus.GRCm39.ncrna.fa.gz': FASTA file of non-coding RNA (NC) transcripts for mouse (GRCm39 genome build).
#
# These files can be downloaded from the tutorial data link (or prepared from genome annotation).
# We use 'read.fasta()' function from 'seqinr' package to read these FASTA files as DNA sequences.

cds_reference_sequences <- read.fasta("data/Mus_musculus.GRCm39.cds.all.fa.gz", seqtype = "DNA", as.string = TRUE, set.attributes = FALSE)
nc_reference_sequences <- read.fasta("data/Mus_musculus.GRCm39.ncrna.fa.gz", seqtype = "DNA", as.string = TRUE, set.attributes = FALSE)

# 'cds_reference_sequences' and 'nc_reference_sequences' now hold the reference CDS and NC RNA sequences, respectively.

###  ================ 4.2: Prepare Sequences for Coding Potential Prediction ================

# We need to define the set of sequences for which we want to predict coding potential.
# You have two options here:

# **Option 1: Use the filtered list of potential lncRNAs ('potential_lncRNA_transcript_ids'):**
# This uses the refined list of transcripts that have passed the initial filtering steps (biotype, length, exon count, expression).
sequences_to_predict <- potential_lncRNA_transcript_ids

# **Option 2: Use the assembled merged transcriptome (without initial filtering):**
# If you want to predict coding potential for the entire assembled transcriptome (all transcripts),
# you can load the merged transcriptome FASTA file here (replace '...' with the actual file path).
# sequences_to_predict <- read.fasta(".../merged_transtriptome.fa", seqtype = "DNA", as.string = TRUE, set.attributes = FALSE)
# For this tutorial, we will proceed with Option 1 (using the filtered 'potential_lncRNA_transcript_ids').

###  ================ 4.3: Split Reference Sequences into Training and Test Sets ================

# To evaluate the performance of coding potential prediction tools, we need to split our
# reference CDS and NC RNA sequence datasets into training and testing sets.
# Training sets are used to train the prediction models (if needed), and test sets are used
# to evaluate their accuracy and performance on unseen data.

# We use the 'test.train.cds()' and 'test.train.nc()' functions (likely from your 'lncRna' package)
# to perform this splitting. We set a seed ('set.seed(12345)') to ensure that the splitting is reproducible,
# meaning that if you run the script again, you will get the same training and test sets.

set.seed(12345) # Set seed for reproducible training/test set splitting
cds_training_test_sets <- test.train.cds(cds.fa = cds_reference_sequences, percent_train = 0.6)
set.seed(12345) # Set seed for reproducible training/test set splitting
nc_training_test_sets <- test.train.nc(nc.fa = nc_reference_sequences, percent_train = 0.6)

# Inspect the structure of the created training/test set lists.
head(cds_training_test_sets$cds.test) # Example: display first few CDS test set IDs
head(nc_training_test_sets$nc.test)  # Example: display first few NC test set IDs

###  ================ 4.4: Prepare Combined Sequence Sets for Training, Testing, and Prediction ================

# Finally, we prepare combined sets of sequences for different purposes:

# **'sequences_to_predict'**:  This variable (which we defined in section 4.2) already contains
#                          the list of transcripts for which we will predict coding potential
#                          (in this tutorial, it's the filtered 'potential_lncRNA_transcript_ids').
#                          We now *extend* this set by adding the *test sets* of known CDS and NC sequences.
#                          This creates a comprehensive set of sequences for prediction, including both
#                          potential lncRNAs and known coding/non-coding RNAs (for testing purposes).
sequences_to_predict <- c(sequences_to_predict,
                          cds_reference_sequences[names(cds_reference_sequences) %in% cds_training_test_sets$cds.test],
                          nc_reference_sequences[names(nc_reference_sequences) %in% nc_training_test_sets$nc.test])

# **'cds_training_sequences'**: This set contains the *training set* of known CDS sequences.
#                               It will be used to train coding potential prediction tools (if training is needed).
cds_training_sequences <- cds_reference_sequences[names(cds_reference_sequences) %in% cds_training_test_sets$cds.train]

# **'nc_training_sequences'**: This set contains the *training set* of known NC sequences.
#                              It will also be used for training coding potential prediction tools.
nc_training_sequences <- nc_reference_sequences[names(nc_reference_sequences) %in% nc_training_test_sets$nc.train]

###  ================ 4.5: Write Sequence Sets to FASTA Files (for external tool input - Optional) ================

# For some coding potential prediction tools, you might need to provide input sequences as FASTA files.
# The following lines write the prepared sequence sets to FASTA files in your working directory.
# These files can then be used as input for external coding potential prediction software
# (e.g., command-line tools, web servers if direct R integration is not available).
#
# **Note:** This step is optional and depends on the workflow of the coding potential prediction tools you intend to use.

write.fasta(sequences_to_predict, names(sequences_to_predict), "seqs2predict.fa", nbchar = 80, as.string = TRUE)
write.fasta(cds_training_sequences, names(cds_training_sequences), "cds2train.fa", nbchar = 80, as.string = TRUE)
write.fasta(nc_training_sequences, names(nc_training_sequences), "nc2train.fa", nbchar = 80, as.string = TRUE)


#  ================ Section 5: Stage 2A - Coding Potential Prediction Analysis ================

# In this section, we will perform coding potential prediction for our set of transcripts
# using several established computational tools. We will then integrate the results from
# these tools into a single table for downstream analysis and comparison.
#
# The coding potential prediction tools used in this tutorial are:
#   - CPC2 (Coding Potential Calculator 2)
#   - FEELnc (Feature-based Evolutionary and Ensemble Learning for lncRNA Classification)
#   - PLEK (Predictor of Long non-coding RNAs and messenger RNAs based on k-mer scheme)
#   - CPAT (Coding Potential Assessment Tool)
#   - CNCI (Coding-Non-Coding Index)
#   - LncFinder (Long non-coding RNA Finder)
#   - (Optional: lncRNA_deep) # Commented out in original script

###  ================ 5.1: Reading Coding Potential Prediction Results (Individual Tools - Optional) ================

# You can read the output files from each coding potential prediction tool individually
# using dedicated functions provided in the 'lncRna' package. This is useful if you want to
# inspect the output of each tool separately before combining them.
#
# **Note:** This step is optional. You can skip to section 5.2 to directly read and combine all results.

# Example of reading results from individual tools:
# CPC2_results <- read.CPC2(".../CPC2.out")
# FEELnc_results <- read.FEELnc(".../feelnc_codpot_out/FEELnc_RF.txt")
# PLEK_results <- read.PLEK(".../PLEK.out")
# # ... and so on for other tools (CNCI, LncFinder, lncRNA_deep if used)

###  ================ 5.2: Calculating CPAT Cutoff Value ================

# CPAT (Coding Potential Assessment Tool) requires a species-specific or dataset-specific
# cutoff value to classify transcripts as coding or non-coding based on its score.
# We use the 'CPATcutoff()' function to calculate this cutoff from the CPAT output feature file.

# CPAT_cutoff_value <- CPATcutoff(".../CPATout.feature.xls")
# # The calculated 'CPAT_cutoff_value' will be used when reading CPAT prediction results.
# # For mouse (Mus musculus), a pre-defined cutoff of 0.64 is often used, as applied in the next step.

###  ================ 5.3: Reading and Combining Coding Potential Results into a Table ================

# For convenient analysis and comparison, we will combine the results from all coding potential
# prediction tools into a single data table. We use the 'CodPot2tbl()' function for this purpose.
# This function reads the output files from each tool and creates a consolidated table
# where each row represents a transcript and columns represent the coding potential scores
# (or binary predictions) from different tools.

coding_potential_table <- CodPot2tbl(
  CPC2_outfile      = "data/lncCodPot_MMus/CPC2_Mm_lnc.txt.txt",
  FEELnc_outfile    = "data/lncCodPot_MMus/FEELnc_codpot_RF.txt",
  CNCI_outfile      = "data/lncCodPot_MMus/CNCI.index",
  CPAT_outfile      = "data/lncCodPot_MMus/CPAT_Mm_lnc.txt",
  CPAT_cutoff       = 0.64, # Using pre-defined cutoff for mouse (or use calculated 'CPAT_cutoff_value' from section 5.2)
  PLEK_outfile      = "data/lncCodPot_MMus/PLEK_Mm_lnc.txt",
  LncFinder_outfile = "data/lncCodPot_MMus/LncFinder_results_more5.csv"
  # lncRNA_Mdeep_outfile = "data/lncCodPot_MMus/Mm107_out.feature.xls" # Optional: Add lncRNA_deep output if used
)

# The 'coding_potential_table' (assigned to 'tbl2' in the original script) now contains the combined
# coding potential prediction results from all specified tools.
head(coding_potential_table) # Inspect the first few rows of the combined table.

###  ================ 5.4: Visualizing Coding Potential Prediction Agreement (Venn Diagrams) ================

# To visualize the agreement and disagreement between different coding potential prediction tools,
# we can use Venn diagrams. The 'venn.CodPot()' function helps to generate these diagrams
# based on the combined coding potential table.

# **Venn diagram for all tools:**
# This generates a Venn diagram showing the overlap in non-coding predictions across all tools in 'coding_potential_table'.
venn.CodPot(CodPot = coding_potential_table)

# **Venn diagram for selected tools and prediction criteria:**
# You can customize the Venn diagram to focus on specific tools and prediction outcomes.
# In this example, 'selmet = c(1,1,0,1,1,0)' selects specific criteria for each tool
# (the meaning of these criteria depends on how 'venn.CodPot' and the coding potential tools are designed).
venn.CodPot(CodPot = coding_potential_table, selmet = c(1,1,0,1,1,0))


#  ================ Section 6: Stage 2B - Best Accuracy Analysis of Coding Potential Prediction Tools ================

# In this section, we will evaluate the accuracy, sensitivity, and specificity of the
# coding potential prediction tools (and their combinations) using our prepared test datasets
# of known coding (CDS) and non-coding (NC) RNA sequences (created in Section 4).
# This analysis helps us to determine the best performing tools and combinations for our lncRNA identification pipeline.

###  ================ 6.1: Calculate Performance Statistics for Individual Tools ================

# The 'SumSingleTools()' function calculates basic performance statistics (like True Positives, False Positives, etc.)
# for each individual coding potential prediction tool based on the test datasets.
# It takes the combined coding potential table ('coding_potential_table'), and the test sets
# for non-coding RNAs ('nc_tt$nc.test') and coding RNAs ('cds_tt$cds.test') as input.

individual_tool_performance <- SumSingleTools(CodPot.tbl2 = coding_potential_table, nc_test = nc_tt$nc.test, cds_test = cds_tt$cds.test)
head(individual_tool_performance) # Inspect the calculated performance statistics.

###  ================ 6.2: Analyze Error Rates for Selected Individual Tools  ================

# The 'BestTool()' function analyzes the error rates (e.g., False Positive Rate, False Negative Rate)
# for a user-specified set of coding potential prediction tools.
# We first define the tools we want to analyze in the 'selectedTools' vector.

selected_tools <- c("CPC2", "PLEK", "FEELnc", "CPAT", "CNCI", "LncFinder") # List of tools to analyze

# Now, use 'BestTool()' to calculate and display error rates for the selected tools.
best_tool_cpt_analysis <- BestTool(BestPat = individual_tool_performance, tools = selected_tools)
best_tool_cpt_analysis # Print the error analysis results.

###  ================ 6.3: Performance Statistics for Combined Tool Predictions (At Least 'n' Tools Criterion) ================

# To improve prediction accuracy, we can combine the predictions from multiple tools.
# One common approach is to classify a transcript as non-coding only if it is predicted as non-coding
# by at least a certain number of tools (e.g., at least 'n' tools).
# The 'SumAtLeast()' function calculates performance statistics for such combined predictions.

combined_tool_performance_atleast_n <- SumAtLeast(BestPat = individual_tool_performance, tools = selected_tools)
head(combined_tool_performance_atleast_n) # Inspect the performance statistics for combined criteria.

###  ================ 6.4: Error Analysis for Combined Tool Predictions (At Least 'n' Tools Criterion) ================

# The 'BestTool.atleast()' function performs error analysis (similar to 'BestTool()')
# but specifically for the combined prediction criteria (at least 'n' tools agreement).
best_tool_atleast_analysis <- BestTool.atleast(BestPat = combined_tool_performance_atleast_n)
best_tool_atleast_analysis # Print the error analysis results for combined criteria.

###  ================ 6.5: Performance Statistics for All Tool Combinations (Venn Diagram Combinations) ================

# To explore all possible combinations of tool predictions (as visualized in the Venn diagram),
# we can calculate performance statistics for each combination.
# The 'SumCombTools()' function calculates these statistics for all combinations of the selected tools.

combined_tool_performance_all_combinations <- SumCombTools(BestPat = combined_tool_performance_atleast_n, selectedTools = selected_tools)
combined_tool_performance_all_combinations # Inspect the performance statistics for all combinations.

###  ================ 6.6: Error Analysis for Selected Tool Combinations ================

# From the comprehensive 'combined_tool_performance_all_combinations' table, we can select
# specific tool combinations that are of interest (e.g., based on Venn diagram visualization or
# initial performance observations).
# The 'BestTool.comb()' function performs error analysis for these selected combinations.

selected_combinations <- colnames(combined_tool_performance_all_combinations)[17:ncol(combined_tool_performance_all_combinations)]
# In this example, we are selecting combinations starting from column 17 (adjust column indices if needed).

best_tool_combination_analysis <- BestTool.comb(BestPat = combined_tool_performance_all_combinations, selectComb = selectedCombinations)
best_tool_combination_analysis # Print the error analysis for selected combinations.

# Example: Identify combinations with Accuracy > 0.8 (optional filtering)
highly_accurate_combinations <- best_tool_combination_analysis[, which(best_tool_combination_analysis[1,] > 0.8), drop = FALSE]
highly_accurate_combinations # Display combinations with Accuracy > 0.8

###  ================ 6.7: Calculate Confusion Matrices for Selected Methods and Metrics ================

# Confusion matrices provide a detailed breakdown of prediction performance, showing
# True Positives, True Negatives, False Positives, and False Negatives.
# The 'calculate_cm()' function can generate confusion matrices for selected methods and performance metrics.

# **Calculate confusion matrices for all combinations with default settings (Accuracy metric):**
all_confusion_matrices <- calculate_cm(bp_cmb_data = best_tool_combination_analysis, best_pat3_data = combined_tool_performance_all_combinations)

# **Calculate confusion matrices and print metric thresholds for methods (default metric: Accuracy):**
all_confusion_matrices_thresholds <- calculate_cm(bp_cmb_data = best_tool_combination_analysis, best_pat3_data = combined_tool_performance_all_combinations, print_metric_threshold_methods = TRUE)

# **Calculate confusion matrices with a specific threshold value (e.g., threshold = 0.9 for Accuracy):**
all_confusion_matrices_threshold_0.9 <- calculate_cm(bp_cmb_data = best_tool_combination_analysis, best_pat3_data = combined_tool_performance_all_combinations, print_metric_threshold_methods = TRUE, threshold = 0.9)

# **Calculate confusion matrices for a specific metric (e.g., "Precision") and return only high-performing methods:**
high_precision_confusion_matrices <- calculate_cm(bp_cmb_data = best_tool_combination_analysis, best_pat3_data = combined_tool_performance_all_combinations, print_metric_threshold_methods = TRUE, metric_to_extract = "Precision", return_only_high_methods = TRUE)

# **Alternatively, return only the list of high-performing methods (meeting the threshold for Precision):**
all_high_precision <- calculate_cm(bp_cmb_data = best_tool_combination_analysis, best_pat3_data = combined_tool_performance_all_combinations, print_metric_threshold_methods = TRUE, return_only_high_methods = TRUE)


#  ================ Section 7: Visualizing Confusion Matrix Statistics - Radar Plots and Clock Plots ================

# In this section, we will explore different ways to visualize the confusion matrix statistics
# calculated in the previous steps. We will use two types of plots: Radar plots and Clock plots,
# both provided by the 'lncRna' package. These plots help to visually compare the performance
# of different coding potential prediction methods and their combinations across various metrics.

###  ================ 7.1: Radar Plots - Visualizing Performance Metrics in a Radial Layout ================

# Radar plots (also known as spider plots or star plots) are useful for displaying multivariate
# data in a two-dimensional chart. In our case, each axis of the radar plot represents a
# performance metric (e.g., Accuracy, Precision, Sensitivity), and each "vertex" or point on the radar
# represents the value of that metric for a specific coding potential prediction method (or combination).

####  ================ 7.1.1: Simple Radar Plot (All Methods, Default Metrics) ================

# If you run 'radar_plot_cm()' with just the list of confusion matrices ('cm_list'), it will generate
# a radar plot for *all* methods in the 'cm_list' and will display a default set of performance metrics
# (typically Accuracy, Sensitivity, Specificity, Precision).
# If no 'methods' are explicitly specified, the function might prompt a console message indicating this.

radar_plot_cm(cm_list = all_high_precision)

####  ================ 7.1.2: Radar Plot for Specified Methods ================

# You can focus the radar plot on a subset of methods by using the 'methods' argument.
# This is helpful when you want to compare the performance of only a few specific methods or combinations.
#
# Example: Create a radar plot comparing "CPC2+CPAT", "PLEK+CPAT", and "CPAT+CNCI" combinations.

radar_plot_cm(cm_list = all_high_precision, methods = c("CPC2+CPAT", "PLEK+CPAT", "CPAT+CNCI"))

####  ================ 7.1.3: Radar Plot for Specified Performance Metrics ================

# By default, 'radar_plot_cm()' displays a standard set of metrics. You can customize
# the metrics displayed on the radar plot using the 'metrics' argument.
# This allows you to focus on specific aspects of performance that are most relevant to your analysis.
#
# Example: Create a radar plot showing only "Sensitivity", "Recall", "Precision", and "Accuracy".

radar_plot_cm(cm_list = all_high_precision, metrics = c("Sensitivity", "Recall", "Precision", "Accuracy"))

####  ================ 7.1.4: Radar Plots in a Multiple Plot Layout (Grid of Plots) ================

# When you have many methods or combinations to compare, displaying them all on a single radar plot
# can become crowded and difficult to read.  The 'layout = "multiple"' option generates a grid of
# individual radar plots, where each plot represents a single method or a small group of methods.
#
# Example: Generate a grid of radar plots, one for each method/combination in 'all_high_precision'.
#          We also use 'display_area = TRUE' to fill the radar plot area, enhancing visual comparison.

radar_plot_cm(cm_list = all_high_precision, layout = "multiple", display_area = TRUE)

####  ================ 7.1.5: Radar Plots without Fill Area ================

# You can remove the filled area under the radar lines by setting 'display_fill = FALSE'.
# This can be useful in some cases for a cleaner look or when comparing many methods where
# filled areas might overlap and obscure each other.
#
# Example: Create multiple radar plots without filled areas.

radar_plot_cm(cm_list = all_high_precision, layout = "multiple", display_area = TRUE, display_fill = FALSE)

####  ================ 7.1.6: Radar Plot with Saving Source Data Frame ================

# radar plot with saving source data frame
radar_plot_cm(cm_list = all_high_precision, layout = "multiple", display_area = TRUE, display_fill = FALSE, save_data = TRUE, file_name = "radar_plot_data_banana")


###  ================ 7.2: Clock Plots - Circular Bar Plots for Performance Metrics ================

# Clock plots are another way to visualize performance metrics. They are essentially circular bar plots
# where each "hour" on the clock represents a performance metric, and the length of the bar represents the metric's value.
# Clock plots can be particularly effective for highlighting differences in metric values in a visually appealing circular format.

####  ================ 7.2.1: Simple Clock Plot (All Methods, Default Metrics) ================

# Similar to radar plots, running 'clock_plot_cm()' with just 'cm_list' will generate clock plots
# for all methods in 'cm_list' using a default set of performance metrics.

clock_plot_cm(cm_list = all_high_precision)
clock_plot_cm(cm_list = all_cms) # Example with 'all_cms' list (if you want to compare with a different set of confusion matrices)

####  ================ 7.2.2: Clock Plots in a Multiple Plot Layout (Grid of Plots) ================

# For comparing multiple methods using clock plots, you can again use 'layout = "multiple"' to create
# a grid of individual clock plots, one for each method or combination.
# This is especially useful when you have a larger number of methods to visualize.
# You can also specify a 'plot_title' which will be used as a base title for each individual clock plot.

clock_plot_cm(cm_list = all_high_precision, layout = "multiple", plot_title = "Coding Potential Prediction Performance")

####  ================ 7.2.3: Clock Plots for Selected Methods ================

# Just like radar plots, you can focus clock plots on specific methods using the 'methods' argument.
# This allows for direct visual comparison of performance between a chosen subset of methods.
#
# Example: Create clock plots only for "CPC2+CPAT", "PLEK+CPAT", and "CPAT+CNCI" combinations.

clock_plot_cm(cm_list = all_high_precision, methods = c("CPC2+CPAT", "PLEK+CPAT", "CPAT+CNCI"))


#  ================ Section 8: Stage 3 - Functional Annotation of Predicted lncRNAs ================

# In this section, we move on to the functional annotation of the lncRNAs identified in the
# previous stages. We will use several approaches to predict or infer the potential functions and
# functional associations of these lncRNAs. This typically involves:
# 1. Refining the list of predicted lncRNAs based on coding potential scores and optional filtering.
# 2. Combining predicted lncRNAs with known lncRNAs to create comprehensive lists.
# 3. Investigating potential cis- and trans-regulatory interactions of lncRNAs with protein-coding genes.
# 4. Performing Gene Ontology (GO) and pathway enrichment analysis on genes interacting with lncRNAs
#    to infer potential functional roles.

###  ================ 8.1: Refining the List of Predicted lncRNAs ================

# If you performed coding potential prediction on a comprehensive transcriptome dataset
# (and not just on pre-filtered potential lncRNAs), you might want to refine your lncRNA list
# based on the coding potential prediction results.

# **Filter based on coding potential scores (if whole transcriptome was used for prediction):**
# This step is conditional - run it ONLY if you performed coding potential prediction on the *entire* transcriptome.
# If you started with a pre-filtered 'pot_lncRNA' list for prediction, you can skip this step,
# as your 'potential_lncRNA_transcript_ids' list is already filtered.

# predicted_lncRNA_candidates <- coding_potential_table[coding_potential_table$seqIDs %in% potential_lncRNA_transcript_ids,] # Use 'potential_lncRNA_transcript_ids' if you used pre-filtered list for prediction
predicted_lncRNA_candidates <- coding_potential_table # If you predicted on the whole transcriptome, use the full coding potential table

# **Apply a threshold based on the number of non-coding predictions:**
# Here, we refine the list to include only transcripts that are predicted as non-coding by
# at least 5 out of the tools used. This increases the confidence in our lncRNA predictions.
# Adjust the threshold (e.g., >= 5) based on your desired stringency.
predicted_lncRNA_candidates <- predicted_lncRNA_candidates[rowSums(predicted_lncRNA_candidates[, 2:ncol(predicted_lncRNA_candidates)]) >= 5,]

# **Optional: Filter out transcripts with PFAM domain annotations (if PFAM analysis was performed):**
# If you have performed PFAM domain analysis and have a list of transcripts with PFAM hits ('pfam' variable),
# you can optionally remove these transcripts from your predicted lncRNA list.
# This is based on the idea that lncRNAs typically lack conserved protein domains.
# predicted_lncRNA_candidates <- predicted_lncRNA_candidates[predicted_lncRNA_candidates$seqIDs %!in% pfam,]

# **Extract the list of predicted lncRNA transcript IDs:**
# Finally, we extract just the transcript IDs from the filtered table to create a list of high-confidence
# predicted lncRNA transcript IDs.
predicted_lncRNA_transcript_ids <- predicted_lncRNA_candidates$seqIDs
head(predicted_lncRNA_transcript_ids) # Display the first few predicted lncRNA IDs.

###  ================ 8.2: Creating Comprehensive lncRNA Lists (Transcripts and Genes) ================

# To work with a comprehensive list of lncRNAs, we combine our *de novo* predicted lncRNAs
# with *known* lncRNAs from the reference annotation (which we extracted in Section 1a and stored in 'known_lncRNA').

# **Combine predicted and known lncRNA transcript IDs:**
# We create a unique list of lncRNA transcript IDs by combining 'predicted_lncRNA_transcript_ids'
# with 'known_lncRNA' and removing any duplicates.
lncRNA_transcript_ids_combined <- unique(c(predicted_lncRNA_transcript_ids, known_lncRNA))
head(lncRNA_transcript_ids_combined) # Display the first few combined lncRNA transcript IDs.

# **Create a list of lncRNA gene IDs:**
# To perform gene-level functional analysis, we need to get the corresponding gene IDs for our
# combined list of lncRNA transcripts. We use the 'stringtieGTF' annotation (merged transcriptome GTF)
# to map transcript IDs to gene IDs.
lncRNA_gene_ids_combined <- unique(stringtieGTF[stringtieGTF$transcript_id %in% lncRNA_transcript_ids_combined,]$gene_id)
head(lncRNA_gene_ids_combined) # Display the first few combined lncRNA gene IDs.

# **Create a list of known protein-coding gene IDs:**
# For comparison and context, we also create a list of known protein-coding gene IDs
# from the reference GTF annotation ('refGTF').
protein_coding_gene_ids <- unique(refGTF[refGTF$gene_biotype %in% "protein_coding",]$gene_id)
head(protein_coding_gene_ids) # Display the first few protein-coding gene IDs.


#  ================ Section 9: Investigating lncRNA-mRNA Interactions (Cis and Trans) ================

# In this section, we will investigate potential functional interactions of our identified lncRNAs
# with protein-coding genes. We will analyze both cis-regulatory interactions (nearby genes)
# and trans-regulatory interactions (gene expression correlations).

### 9.1: Cis-Regulatory Interaction Analysis

# **Identify cis-interacting protein-coding genes:**
# We use the 'cisInter()' function to identify protein-coding genes that are located within a
# certain genomic distance (e.g., 10kb) of our lncRNA transcripts. Cis-regulation implies that
# lncRNAs might regulate the expression of nearby genes on the same chromosome.

# The 'cisInter()' function requires:
#   - 'is.best = TRUE':  Indicates that we want to use the "best" annotation set (Stringtie merged GTF).
#   - 'FEELnc.classes':  FEELnc classification output (used for filtering or weighting interactions, if available).
#   - 'lncRNAs':  The list of lncRNA transcript IDs ('lncRNA_transcript_ids_combined').
#   - 'lncRNA.level = "transcript"': Specifies that lncRNAs are defined at the transcript level.
#   - 'mRNA.level = "gene"': Specifies that protein-coding genes (mRNAs) are defined at the gene level.
#   - 'max.dist = 10000': Maximum genomic distance (in base pairs) to consider for cis-interaction (10kb in this example).
#   - 'mRNAs':  List of protein-coding gene IDs to consider for interactions (we use differentially expressed genes 'rownames(DEGs)').

cis_interaction_table <- cisInter(is.best = TRUE,
                                  FEELnc.classes = "data/lncCodPot_MMus/FEELnc_Mm_classes.txt",
                                  lncRNAs = lncRNA_transcript_ids_combined,
                                  lncRNA.level = "transcript",
                                  mRNA.level = "gene",
                                  max.dist = 10000,
                                  mRNAs = rownames(DEGs)) # Using differentially expressed genes (DEGs) as target mRNAs
head(cis_interaction_table) # Inspect the resulting table of cis-interactions.

###  ================ 9.2: Trans-Regulatory Interaction Analysis ================

# **Identify trans-interacting protein-coding genes based on expression correlation:**
# We use the 'TransAct()' function to identify potential trans-regulatory interactions based on
# gene expression correlations between lncRNAs and protein-coding genes across samples.
# Trans-regulation suggests that lncRNAs might influence the expression of distant genes, possibly on different chromosomes.

# **Important Note:** Ensure that the row names of your 'genes_counts' data frame are cleaned (gene IDs without "|..." suffix)
#                 as mentioned in the data loading section, before running 'TransAct()'.

# The 'TransAct()' function requires:
#   - 'expr.matrix = genes_counts':  Gene expression count matrix (cleaned row names are important!).
#   - 'rval = 0.95':  Minimum absolute Pearson correlation coefficient (rho) to consider for interaction (0.95 in this example - high positive or negative correlation).
#   - 'pval = 0.05':  Maximum adjusted p-value for correlation significance (0.05 FDR threshold in this example).
#   - 'lncRNA.list = row.names(DELs)': List of lncRNA gene IDs (we use differentially expressed lncRNAs 'rownames(DELs)').
#   - 'tarRNA.list = rownames(DEGs)': List of target protein-coding gene IDs (we use differentially expressed genes 'rownames(DEGs)').

trans_interaction_table <- TransAct(expr.matrix = genes_counts,
                                    rval = 0.95,
                                    pval = 0.05,
                                    lncRNA.list = rownames(DELs), # Using differentially expressed lncRNAs (DELs)
                                    tarRNA.list = rownames(DEGs)) # Using differentially expressed genes (DEGs) as target mRNAs
head(trans_interaction_table) # Inspect the resulting table of trans-interactions.


#  ================ Section 10: Functional Enrichment Analysis of lncRNA-Interacting Genes (gProfiler2) ================

# Now that we have lists of protein-coding genes potentially interacting with lncRNAs (cis and trans),
# we can perform functional enrichment analysis to understand the potential biological pathways and functions
# associated with these interactions. We will use the 'gost()' function from the 'gprofiler2' package
# for Gene Ontology (GO), pathway, and other enrichment analyses.

###  ================ 10.1: Functional Enrichment Analysis of Cis-Interacting Genes ================

# **Run gProfiler2 'gost()' for cis-interacting genes:**
# We use the 'gost()' function to perform enrichment analysis on the list of protein-coding genes
# found to be in cis-interaction with lncRNAs ('cis_interaction_table$partnerRNA_gene').

# Refer to the gProfiler2 documentation ('?gost') for detailed explanation of all parameters.
# Key parameters used here:
#   - 'query':  The list of gene IDs to be analyzed (cis-interacting genes).
#   - 'organism = "mmusculus"': Specifies mouse as the organism.
#   - 'ordered_query = FALSE':  Indicates that the gene list is not ranked.
#   - 'multi_query = FALSE':  We are analyzing a single gene list (not multiple lists).
#   - 'significant = TRUE':  Only return statistically significant enrichment results (p-value <= user_threshold).
#   - 'user_threshold = 0.05':  Significance threshold for adjusted p-values (FDR).
#   - 'correction_method = "g_SCS"':  Multiple testing correction method (using gSCS algorithm - see gProfiler2 documentation).
#   - 'sources = NULL':  Analyze against all available data sources in gProfiler2 (GO, KEGG, Reactome, etc.).

cis_enrichment_results <- gost(query = cis_interaction_table$partnerRNA_gene,
                               organism = "mmusculus", ordered_query = FALSE,
                               multi_query = FALSE, significant = TRUE, exclude_iea = FALSE,
                               measure_underrepresentation = FALSE, evcodes = TRUE,
                               user_threshold = 0.05, correction_method = "g_SCS",
                               domain_scope = "annotated", custom_bg = NULL,
                               numeric_ns = "", sources = NULL, as_short_link = FALSE)

# **Extract the enrichment results table:**
# The 'gost()' function returns a list. We access the results table using '$result'.
cis_gProfiler_results_table <- cis_enrichment_results$result
head(cis_gProfiler_results_table) # Inspect the enrichment results for cis-interacting genes.

###  ================ 10.2: Functional Enrichment Analysis of Trans-Interacting Genes ================

# **Repeat gProfiler2 'gost()' for trans-interacting genes:**
# Perform the same functional enrichment analysis for the list of trans-interacting protein-coding genes
# ('trans_interaction_table$targetRNA.id').

trans_enrichment_results <- gost(query = trans_interaction_table$targetRNA.id,
                                 organism = "mmusculus", ordered_query = FALSE,
                                 multi_query = FALSE, significant = TRUE, exclude_iea = FALSE,
                                 measure_underrepresentation = FALSE, evcodes = TRUE,
                                 user_threshold = 0.05, correction_method = "g_SCS",
                                 domain_scope = "annotated", custom_bg = NULL,
                                 numeric_ns = "", sources = NULL, as_short_link = FALSE)

# **Extract the enrichment results table:**
trans_gProfiler_results_table <- trans_enrichment_results$result
head(trans_gProfiler_results_table) # Inspect the enrichment results for trans-interacting genes.

###  ================ 10.3: LncTar-Functional Enrichment Analysis of lncRNA-mRNA Interaction Targets ================

# 10.3.1Prepare Input Files for LncTar Analysis ================
  
  # In this step, we will prepare the necessary input files for LncTar, a tool used for
  # predicting lncRNA-mRNA interactions. LncTar requires FASTA files containing the
  # sequences of lncRNAs and target mRNAs of interest. We will generate these FASTA files
  # using our differentially expressed lncRNAs (DELs) and protein-coding genes (DEGs).
  
# 10.3.2: Prepare mRNA Sequences (DEGs_seqs) for LncTar ----------------------------------

# We will extract the transcript sequences of our differentially expressed protein-coding genes (DEGs)
# from the `stringtieGTF` annotation and the `transcriptome` sequence data.

# Assuming 'stringtieGTF', 'DEGs', 'DELs', 'lncRNA_transcripts', and 'transcriptome' are already loaded.

# Inspect the structure of 'stringtieGTF' data frame.
head(stringtieGTF)

# Extract transcript IDs of differentially expressed genes (DEGs) from 'stringtieGTF'.
DEGs_seqs <- stringtieGTF[stringtieGTF$gene_id %in% rownames(DEGs),]$transcript_id
head(DEGs_seqs) # View the first few DEGs transcript IDs.

# Retrieve the actual sequences for these DEGs transcripts from the 'transcriptome' object.
DEGs_seqs <- transcriptome[names(transcriptome) %in% DEGs_seqs]
head(DEGs_seqs) # Inspect the first few DEG sequences.

# 10.3.3: Prepare lncRNA Sequences (DELs_seqs) for LncTar --------------------------------

# Similarly, we extract the transcript sequences of our differentially expressed lncRNAs (DELs).
# First, we get the transcript IDs of DELs from 'stringtieGTF'.
DELs_seqs <- stringtieGTF[stringtieGTF$gene_id %in% rownames(DELs),]$transcript_id

# We need to ensure that these DELs transcript IDs are indeed within our list of lncRNA transcripts
# ('lncRNA_transcripts', created in an earlier step, likely during data loading and annotation).
DELs_seqs <- DELs_seqs[DELs_seqs %in% lncRNA_transcripts]

# It's good practice to check for any overlap between DEGs and DELs transcript lists.
# While they should ideally be distinct sets, this check confirms no accidental overlap.
sum(DELs_seqs %in% DEGs_seqs) # Should ideally be 0, or a very small number if any overlap is expected.

# Retrieve the actual sequences for these DELs transcripts from the 'transcriptome' object.
DELs_seqs <- transcriptome[names(transcriptome) %in% DELs_seqs]
head(DELs_seqs) # Inspect the first few DEL sequences.

# 10.3.4: Write Sequences to FASTA Files for LncTar -------------------------------------

# LncTar requires input sequences to be in FASTA format. We will now write the prepared
# mRNA (DEGs_seqs) and lncRNA (DELs_seqs) sequences to separate FASTA files.

# Write DEGs (mRNA) sequences to 'DEGs_seqs.fa' file.
write.fasta(DEGs_seqs, names(DEGs_seqs), "DEGs_seqs.fa", nbchar = 80, as.string = T)
cat("mRNA sequences for DEGs saved to 'DEGs_seqs.fa'\n")

# Write DELs (lncRNA) sequences to 'DELs_seqs.fa' file.
write.fasta(DELs_seqs, names(DELs_seqs), "DELs_seqs.fa", nbchar = 80, as.string = T)
cat("lncRNA sequences for DELs saved to 'DELs_seqs.fa'\n")

# 10.3.5: Download and Set Up LncTar Tool (Terminal Instructions) ------------------------

# LncTar is a command-line tool that needs to be downloaded and set up separately.
# Please follow these steps in your system's terminal (not in R):

# 1. Navigate to the directory where you intend to run LncTar analysis.
#    For example, if you want to run LncTar in your current working directory, use:
#    `cd path/to/your/working/directory`
#    (Replace 'path/to/your/working/directory' with the actual path).

# 2. Download and unpack the LncTar tool. The download method may vary depending on where you obtain LncTar.
#    If you have a direct download link or instructions from the LncTar developers, follow those.
#    (Example command - you might need to adjust this based on the actual download and archive format):
#    `wget <LncTar_download_link.tar.gz>`
#    `tar -zxvf <LncTar_download_link.tar.gz>`
#    (Replace `<LncTar_download_link.tar.gz>` with the actual download link/filename).

# 3. Set the PERL5LIB environment variable. LncTar is written in Perl and requires
#    the PERL5LIB environment variable to be set to the LncTar directory so that Perl
#    can find the necessary LncTar libraries. Use the following command, replacing
#    '/path/to/LncTar' with the actual path to the LncTar directory you unpacked:
#    `export PERL5LIB=/path/to/LncTar:$PERL5LIB`

#    **Important Notes:**
#    - You need to run these commands in your terminal (e.g., bash, zsh, Command Prompt on Windows).
#    - The `export PERL5LIB` command typically needs to be run in each new terminal session
#      where you want to use LncTar, or you can add it to your shell's configuration file (e.g., .bashrc, .zshrc)
#      to make it persistent across sessions.
#    - Refer to the LncTar documentation for the most accurate and up-to-date instructions
#      on downloading, installation, and setup, as the specific steps might change.

# After completing these terminal setup steps, you will be ready to run LncTar
# using the 'DEGs_seqs.fa' (mRNA sequences) and 'DELs_seqs.fa' (lncRNA sequences) files
# that we have just created. The next step in your workflow would typically involve
# executing LncTar from the terminal with these input FASTA files.

# **Analyze functional enrichment of target genes from lncRNA-mRNA interaction predictions (LncTar):**
# If you have lncRNA-mRNA interaction predictions (e.g., from LncTar tool, loaded from 'data/DELs_vs_DEGs_LncTar.txt'),
# you can perform enrichment analysis on the target genes of these predicted interactions.

# 10.3.6LncTar output analysis ----------------
# **Load LncTar interaction data:**
LncTar_interaction_data <- read.table(file = "data/DELs_vs_DEGs_LncTar.txt", header = TRUE)

# **Run gProfiler2 'gost()' for LncTar target genes:**
LncTar_enrichment_results <- gost(query = LncTar_interaction_data$Target, # 'Target' column contains the target gene IDs
                                  organism = "mmusculus", ordered_query = FALSE,
                                  multi_query = FALSE, significant = TRUE, exclude_iea = FALSE,
                                  measure_underrepresentation = FALSE, evcodes = TRUE,
                                  user_threshold = 0.05, correction_method = "g_SCS",
                                  domain_scope = "annotated", custom_bg = NULL,
                                  numeric_ns = "", sources = NULL, as_short_link = FALSE)

# **Extract the enrichment results table:**
LncTar_gProfiler_results_table <- LncTar_enrichment_results$result
head(LncTar_gProfiler_results_table) # Inspect enrichment results for LncTar target genes.


# Original script had an extra 'Test' object creation which seems redundant, so it's removed here.


###  ================ 10.4: LION-RNA-Protein Interaction Analysis  ================

# 10.4.1. Install and Load LION Package -------------------------------------------------

# LION (Ligand Interaction Optimized N-terminal) is a tool for predicting RNA-protein interactions.
# We will use it to predict interactions between our differentially expressed lncRNAs (DELs_seqs)
# and differentially expressed proteins (proteins).

# First, install the LION package from GitHub.
# Run this command in R console if you haven't installed LION yet:
# if (!library("devtools", logical.return = T)) install.packages("devtools")
# devtools::install_github("HAN-Siyu/LION")

# Load the LION package
library(LION)

# 10.4.2. Prepare Protein Sequences for LION ---------------------------------------------

# LION requires protein sequences in FASTA format. We will use protein sequences
# corresponding to our differentially expressed protein-coding genes (DEGs_prot).

# Assuming 'refGTF' and 'DEGs' are already loaded from previous steps.

# Extract protein-coding transcripts from the reference GTF
DEGs_prot <- refGTF
DEGs_prot <- DEGs_prot[DEGs_prot$transcript_biotype %in% "protein_coding",]
DEGs_prot <- DEGs_prot[DEGs_prot$gene_id %in% rownames(DEGs),]
DEGs_prot <- unique(DEGs_prot$protein_id)
DEGs_prot <- DEGs_prot[!is.na(DEGs_prot)]
DEGs_prot

# Load the proteome FASTA file
proteome <- read.fasta("data/Mus_musculus.GRCm39.pep.all.fa.gz", seqtype = "AA", as.string = F, set.attributes = T)
names(proteome) <- sub("\\..*", "", names(proteome))
head(proteome)

# Subset proteome to include only differentially expressed proteins
proteins <- proteome[names(proteome) %in% DEGs_prot]
length(proteins)

# Save protein sequences to FASTA file (optional, but good practice)
write.fasta(proteins, names(proteins), "proteins.fa", nbchar = 80)

head(proteins)

# 10.4.3: Run LION Interaction Prediction ---------------------------------------------

# Now we will use the 'run_lion_analysis' function  to perform the
# RNA-protein interaction prediction using LION. This function will process all pairwise
# combinations of your RNA and protein sequences and save the results to a CSV file.
# Execute LION analysis using prepared sequences.
# The results will be saved to 'LION_results.csv' (default) in your working directory.
LION_interaction_data <- run_lion_analysis(rna_seqs = DELs_seqs, prot_seqs = proteins, output_filename = "LION_results.csv", parallel_cores = 8)

#if there is a problem with this function, uncomment code below

# # reading FASTA using seqinr library
# # rna_seqs <- DELs_seqs[1:4]
# # prot_seqs <- proteins[1:2]
# 
# rna_seqs <- DELs_seqs
# prot_seqs <- proteins
# 
# head(rna_seqs)
# head(prot_seqs)
# 
# names(rna_seqs)
# names(prot_seqs)
# 
# # check if both files contain sequences
# if (length(rna_seqs) < 2 | length(prot_seqs) < 2) {
#   stop("Each FASTA file must contain at least 2 sequences for analysis!")
# }
# 
# # //////////////////////////////////////////////////////////////////////////////
# 
# # Creation of combination RNA & Protein
# combinations <- expand.grid(RNA = names(rna_seqs), Protein = names(prot_seqs))
# nrow(combinations)
# 
# # Check if combinations is in pairs
# if (nrow(combinations) %% 2 == 1) {
#   combinations <- rbind(combinations, combinations[nrow(combinations), ])  
# }
# 
# total_combinations <- nrow(combinations) / 2
# combination_counter <- 0  # Licznik aktualnej kombinacji
# 
# # Creating new variable
# LION_res <- NULL
# 
# # Iteration on pairs
# for (i in seq(1, nrow(combinations), by = 2)) {
#   
#   # Select RNA vs Protein)
#   rna_name_1 <- combinations$RNA[i]
#   rna_name_2 <- combinations$RNA[i+1]
#   prot_name_1 <- combinations$Protein[i]
#   prot_name_2 <- combinations$Protein[i+1]
#   
#   # Creation of variables: rna_subset i prot_subset 
#   rna_subset <- list(
#     rna_seqs[[rna_name_1]],
#     rna_seqs[[rna_name_2]]
#   )
#   names(rna_subset) <- c(rna_name_1, rna_name_2)
#   
#   prot_subset <- list(
#     prot_seqs[[prot_name_1]],
#     prot_seqs[[prot_name_2]]
#   )
#   names(prot_subset) <- c(prot_name_1, prot_name_2)
#   
#   combination_counter <- combination_counter + 1
#   
#   # # show names of rna_subset & prot_subset
#   # cat("RNA sequence name in rna_subset:\n")
#   # print(names(rna_subset))
#   # cat("Protein sequence name in prot_subset:\n")
#   # print(names(prot_subset))
#   
#   # Show information of curently analysed combination
#   cat("\n Currently analyzed set:", combination_counter, "/", total_combinations,"\n") 
#   cat(sprintf("progress: %.2f%%\n", (combination_counter/total_combinations)*100))
#   cat("RNA:", names(rna_subset)[1], "vs. Protein:", names(prot_subset)[1], "\n")
#   cat("RNA:", names(rna_subset)[2], "vs. Protein:", names(prot_subset)[2], "\n\n")
#   
#   # analysis
#   Res_conf <- run_confidentPrediction(seqRNA = rna_subset, seqPro = prot_subset,
#                                       methods = c("RPISeq_retrain",
#                                                   "rpiCOOL_retrain",
#                                                   "LION"),
#                                       label = "Interact", # Opcjonalna etykieta
#                                       parallel.cores = 8)
#   
#   # conversion to data frame
#   Res_conf_df <- do.call("cbind", Res_conf)
#   Res_conf_df <- Res_conf_df[!duplicated(names(Res_conf_df))]
#   
#   if (is.null(LION_res)) {
#     LION_res <- Res_conf_df
#   } else {
#     LION_res <- rbind(LION_res, Res_conf_df)
#   }
#   
#   # add result every iteration
#   write.csv2(LION_res, "LION_results.csv", row.names = FALSE)
#   cat("The results have been saved in LION_results.csv\n")
# }
# 
# cat("Analysis completed. Saved all results to ",getwd()," LION_results.csv\n")



# 10.4.5 LION output analysis -----------------------

# If you have protein-lncRNA interaction predictions (e.g., from LION tool, loaded from 'data/LION_results_part.csv'),
# you can also perform functional enrichment analysis on the protein partners of lncRNAs.

# **Load LION interaction data:**
LION_interaction_data <- read.csv2(file = "data/LION_results_part.csv", header = TRUE)

# **(Optional) Explore LION interaction predictions:**
# These lines are for exploring the number of predicted interactions from different LION prediction methods.
nrow(LION_interaction_data[LION_interaction_data$RPISeq_retrain_pred %in% "Interact", ])
nrow(LION_interaction_data[LION_interaction_data$rpiCOOL_retrain_pred %in% "Interact", ])
nrow(LION_interaction_data[LION_interaction_data$LION_pred %in% "Interact", ])

# **(Optional) List interacting protein names based on LION prediction:**
LION_interacting_proteins <- LION_interaction_data[LION_interaction_data$LION_pred %in% "Interact", ]$Pro_Name
head(LION_interacting_proteins)

# **Prepare lists of interacting proteins from different LION methods (for combined enrichment analysis):**
LION_proteins_method1 <- LION_interaction_data[LION_interaction_data$LION_pred %in% "Interact", ]$Pro_Name
LION_proteins_method2 <- LION_interaction_data[LION_interaction_data$rpiCOOL_retrain_pred %in% "Interact", ]$Pro_Name
LION_proteins_method3 <- LION_interaction_data[LION_interaction_data$RPISeq_retrain_pred %in% "Interact", ]$Pro_Name

# **Run gProfiler2 'gost()' for LION-interacting proteins (using combined protein lists):**
LION_enrichment_results <- gost(query = c(LION_proteins_method1, LION_proteins_method2, LION_proteins_method3),
                                organism = "mmusculus", ordered_query = FALSE,
                                multi_query = FALSE, significant = TRUE, exclude_iea = FALSE,
                                measure_underrepresentation = FALSE, evcodes = TRUE,
                                user_threshold = 0.05, correction_method = "g_SCS",
                                domain_scope = "annotated", custom_bg = NULL,
                                numeric_ns = "", sources = NULL, as_short_link = FALSE)

# **Extract the enrichment results table:**
LION_gProfiler_results_table <- LION_enrichment_results$result
head(LION_gProfiler_results_table) # Inspect enrichment results for LION-interacting proteins.
head(LION_interaction_data) # Example: inspect LION interaction data table

###  ================ 10.5: Processing and Merging Interaction Results with Enrichment Data ================

# To combine the interaction data (cis, trans, LncTar, LION) with their corresponding functional enrichment results,
# we use the 'interactions_merge()' function. This function takes the gProfiler2 enrichment results and the
# interaction tables and merges them, adding relevant enrichment information to each interaction record.

# **Process interactions and merge with gProfiler2 results:**

# **Note:** The 'type' argument is used for labeling the interaction type in the merged table.
#         For 'Trans' and 'Cis' interactions, use the enrichment results ('trans_gostres', 'cis_gostres')
#         calculated earlier. For 'LncTar' interactions, use 'LncTar_gostres'.
#         calculated earlier. For 'LION' interactions, use 'LION_gostres'.

Trans_interactions_processed <- process_interactions(gprof = trans_enrichment_results, interaction_table = trans_interaction_table, type = "trans") 
Cis_interactions_processed <- process_interactions(gprof = cis_enrichment_results, interaction_table = cis_interaction_table, type = "cis")
LncTar_interactions_processed <- process_interactions(gprof = LncTar_enrichment_results, interaction_table = LncTar_interaction_data, type = "LncTar", lncRNA_col = "Query", target_col = "Target")
LION_interactions_processed <- process_interactions(gprof = LION_enrichment_results, interaction_table = LION_interaction_data, type = "LION", lncRNA_col = "RNA_Name", target_col = "Pro_Name")


###  ================ 10.6: Combining and Inspecting All Processed Interaction Tables ================

# Finally, we combine all processed interaction tables (cis, trans, LncTar, LION) into a single table
# for a comprehensive overview of potential lncRNA functional associations.

combined_interactions_table <- rbind(Trans_interactions_processed, Cis_interactions_processed, LncTar_interactions_processed, LION_interactions_processed) # Using processed interaction objects directly
combined_interactions_table # View the combined interaction table.


#  ================ Section 11: Visualizing Functional Interaction Results ================

# In this section, we will demonstrate different functions for visualizing the functional interaction
# results summarized in the 'combined_interactions_table'. These plotting functions allow you to explore
# and present the functional associations of lncRNAs from different perspectives.

###  ================ 11.1: Plot Interactions by lncRNA (Bar Plot for Specific lncRNAs) ================

# The 'plot_by_lnc()' function creates a bar plot showing the number of interactions for
# specific lncRNAs of interest. You can select which lncRNAs to display using the 'select_lnc' argument.

# **Example: Bar plot showing interactions for lncRNAs "ENSMUSG00000106858" and "ENSMUSG00000002769", with labels.**
plot_by_lnc(data = combined_interactions_table, select_lnc = c("ENSMUSG00000106858", "ENSMUSG00000002769"), label = TRUE)

###  ================ 11.2: Plot Interactions by Target Gene (Bar Plot for Specific Target Genes) ================

# The 'plot_by_target()' function is similar to 'plot_by_lnc()', but it creates a bar plot
# showing interactions for specific target protein-coding genes.  Use 'select_target' to choose target genes.

# **Example: Bar plot showing interactions for target genes "ENSMUSG00000000731" and "ENSMUSG00000000732", with labels.**
plot_by_target(data = combined_interactions_table, select_target = c("ENSMUSG00000000731","ENSMUSG00000000732"), label = TRUE)

###  ================ 11.3: Plot Interactions by GO/Pathway Terms (Bar Plot for Specific Functional Terms) ================

# The 'plot_by_terms()' function visualizes interactions associated with specific GO terms or pathways.
# Use 'select_terms' to specify the GO terms or pathway descriptions you are interested in.

# **Example 1: Bar plot showing interactions associated with "response to stress" GO term, with labels.**
plot_by_terms(data = combined_interactions_table, select_terms = "response to stress", label = TRUE)

# **Example 2: Bar plot for 'Test' interaction data (note: 'Test' object name might be a remnant, consider using 'LncTar_interactions_processed' instead), with labels.**
plot_by_terms(data = LncTar_interactions_processed, label = TRUE) # Using 'LncTar_interactions_processed' - corrected object name

###  ================ 11.4: Plot Interactions by Interaction Type (Stacked Bar Plot) ================

# The 'plot_by_type()' function likely creates
# a stacked bar plot summarizing interactions

# **Example 1: Basic 'plot_by_type()' plot for combined interactions, with labels.**
plot_by_type(data = combined_interactions_table, label = TRUE)

# **Example 2: 'plot_by_type()' for 'Cis' interactions only, specifying 'type = "cis"', with labels.**
plot_by_type(data = Cis_interactions_processed, type = "cis", label = TRUE)

# **Example 3: 'plot_by_type()' for combined 'cis' and 'LncTar' interaction types, with labels.**
plot_by_type(data = combined_interactions_table, type = c("cis", "LncTar"), label = TRUE)