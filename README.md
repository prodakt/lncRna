# lncRna <img src="img/lncRna_logo_small.png" align="right" height = 150/>

is the R package for lncRNA identification i a simple way.

This package allows to carry out the lncRNA identification pipeline in a few very simple steps. In general the pipieline consist of a few stages:
<ul>
  <b>I. Annotated features:</b>
  <li>extraction of known lncRNA from reference GTF,</li>
  <li>filtering potential (unknown) lncRNA based on the features such as sequence length, exon number,</li>
</ul>
<ul>  
  <b>II. Coding potential</b>
  <li>lncRNA classification based on the coding potential</li>
  <li>filtering transcripts basing on the simmilarity with known nucleotide and peptide sequences (homologues in databases),</li>
</ul>
<ul>  
  <b>III. Functions</b>
  <li>detection of cis and trans acting genes,</li>
  <li>functional analyses</li>
</ul>
<ul>  
  <b>IV. Structure</b>
  <li>under construction</li>
</ul>

-------------------------------------------------------------
## How to install
First you need to install and load the '[devtools](https://github.com/r-lib/devtools)' package in R. 
```
# Install devtools from CRAN
install.packages("devtools")
# load the library
library(devtools)
```
Next you should download the 'lncRna' library from GitHub and load it in your environment:
```
install_github("prodakt/lncRna")
library("lncRna")
```
-------------------------------------------------------------
## Rapid pipeline (first fast run)

1. First you need to install/load the '[rtracklayer](https://www.bioconductor.org/packages/release/bioc/html/rtracklayer.html)' library to import any GTF and GFF files in a acurate format.
```
install.packages("rtracklayer")
library("rtracklayer")
```
2. Run `??lncRna` to list the available functions in the library.
3. Run the functions of 'lncRna' library:

### Ia. Annotated features 
the first stage is to read annotation files (reference GTF - prefered downloaded from ENSEMBL database and GTF generated during or after mapping reads - prefered GTF file merged by Stringtie)
```
# reading GTF files
stringtieGTF <- import.gff("stringtie/stringtie_merged.gtf")
refGTF <- import.gff("reference.gtf") # prefered downloaded from ENSEMBL

# extracting from GTF merged with stringtie the basic features for lncRNA identification
tab1 <- strGTF2stat(stringtieGTF = stringtieGTF)
head(tab1)
pot_lncRNA <- tab1[tab1$exons >1 & tab1$trans_length > 200,]$transcript_id 
head(pot_lncRNA)


# extraction of known lncRNA
known_biotypes <- refBiotypes(refGTF = refGTF)
# what kind and quantity of biotypes do we have in the reference genome
table(known_biotypes$transcript_biotype) 
# the list of known lncRNA transcripts ID 
known_lncRNA <- known_biotypes[known_biotypes$transcript_biotype %in% "lncRNA",]$transcript_id # the list of lncRNA ID's
#
# extraction of known protein coding transcripts
known_pcRNA <- known_biotypes[known_biotypes$transcript_biotype %in% "protein coding",]$transcript_id # the list of protein coding RNA ID's
```

### Ib. Expression level
To filter out low expressed transcripts you can use 'count_matrix" file:
```
transcripts_counts <- read.table("../transcript_count_matrix.csv", header = T, sep = ",", row.names = 1)
expr <- rownames(transcripts_counts[rowSums(transcripts_counts) > 10,])
```
or you can use 'strtie2expr()' function, but this function works only if you used counting option with [Stringtie](http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual)
```
strtie2expr(strdir = "stringtie_folder/", expunit = "FPKM" or "TPM")
```

### IIa. Coding potential
the second stage is reading the output files generated by codding potential tools:
```
# you can read all results separately
CPC2 <- read.CPC2(".../CPC2.out")
FEELnc <- read.FEELnc(".../feelnc_codpot_out/FEELnc_RF.txt")
PLEK <- read.PLEK(".../PLEK.out")
# and so on ...

# CPAT requires calculation of cutoff value
CPATcutoff <- CPATcutoff(".../CPATout.feature.xls") # 
CPAT <- read.CPAT(CPAT_outfile = ".../CPAT.out", CPAT_cutoff = CPATcutoff)

# or you can read and convert to table all results using one function
tbl2 <- CodPot2tbl(CPC2_outfile = ".../CPC2.out",
                   FEELnc_outfile = ".../feelnc_codpot_out/FEELnc_RF.txt",
                   CPAT_outfile = ".../CPAT.out",
                   CPAT_cutoff = 0.78, # the CPAT_cutor is predefined for some organisms (0.78 for human) or you can calculate it using 'CPATcutoff()' function
                   PLEK_outfile = ".../PLEK.out",
                   LncFinder_outfile = ".../LncFinder_results.csv",
                   lncRNA_Mdeep_outfile = ".../Mdeep.out")
                   

head(tbl2)
```
It is not necessary to read all mentioned files. If you don't have some of the results you can simply omit arguments, i.e.:
```
tbl2 <- CodPot2tbl(CPC2_outfile = ".../CPC2.out", PLEK_outfile = ".../PLEK.out")
```
You can easily draw the venn diagram for all used methods:
```
venn.CodPot(CodPot = CodPot)
```


or you can selet which results you wish to include in the venn diagram:
```
venn.CodPot(CodPot = CodPot, selmet = c(1,1,0,1,1,0,0))
```

### IIb. Filtering by simmilarity
in this stage you can read the Pfam scanning output file to filter out transcripts containing protein domains
```
# pfam
pfam <- read.pfam(pfam_outfile = ".../PFAM.out", eval_cutoff = 0.001)
head(pfam)
```
The 'read.rfam()' function allows you to read Rfam output to tabular format.
```
rfam <- read.rfam(rfam_outfile = ".../Rfam.out")
```
### III. Functions
the third stage is to predict or estimate some functions and functional connections of identified lncRNAs
```
# cis acting genes
lncRNA_transcripts <- tbl2[SELECT_ROWS,]$seqIDs
cis <- filter.CisAct(is.best = T, FEELnc.classes = ".../FEELnc_classes.txt", lncRNAs = lncRNA_transcripts)  

```

