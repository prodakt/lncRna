#' Calculate Performance Statistics for Individual Tools
#'
#' Computes confusion matrix statistics (accuracy, precision, recall, etc.)
#' for selected coding potential prediction tools using results prepared by
#' `SumSingleTools`. Allows interactive selection if specific tools are not provided.
#'
#' @param SumSingleTools_list A list generated by `SumSingleTools()`, containing
#'                            `$tools` (list of 0/1 prediction vectors), and
#'                            `$isNC` (numeric vector of true labels: 1=nc, 0=cds).
#' @param tools An optional character vector specifying the names of the tools
#'              (from `names(SumSingleTools_list$tools)`) to analyze. If `NULL` (default),
#'              the user will be prompted to select tools interactively.
#' @param digits The number of decimal places to round the final statistics to (default: 4).
#'
#' @return A data frame where rows are performance metrics (combined overall and by-class)
#'         and columns correspond to the selected tools, rounded to the specified
#'         number of digits. Returns `NULL` if validation fails, no tools are selected,
#'         or no statistics can be calculated.
#' @keywords confusion matrix accuracy performance caret lncRNA validation statistics
#' @export
#' @examples
#' # Ensure 'caret' and necessary helper functions are available
#'
#' if (requireNamespace("caret", quietly = TRUE) &&
#'     exists(".validate_input_list") && exists(".select_tools_interactively") &&
#'     exists(".validate_tool_names") && exists(".calculate_single_tool_stats")) {
#'
#'   # --- Create Example Data (mimicking SumSingleTools output) ---
#'   set.seed(123) # for reproducibility
#'   n_seq <- 50
#'   example_summary_list <- list(
#'     seqIDs = paste0("Seq", 1:n_seq), # seqIDs is not strictly needed by BestTool but often present
#'     tools = list(
#'       CPC2 = sample(c(0, 1), n_seq, replace = TRUE, prob = c(0.3, 0.7)),
#'       CPAT = sample(c(0, 1), n_seq, replace = TRUE, prob = c(0.4, 0.6)),
#'       PLEK = sample(c(0, 1), n_seq, replace = TRUE, prob = c(0.5, 0.5)),
#'       FEELnc = rep(1, n_seq) # Tool that might produce NAs for some metrics
#'     ),
#'     type = sample(c("nc", "cds"), n_seq, replace = TRUE), # Not used by BestTool directly
#'     isNC = NULL # Will be derived
#'   )
#'   example_summary_list$isNC <- ifelse(example_summary_list$type == "nc", 1, 0)
#'
#'   # --- Example 1: Analyze specific tools ---
#'   selected_tool_names <- c("CPC2", "CPAT", "FEELnc")
#'   performance_stats_specific <- BestTool(SumSingleTools_list = example_summary_list,
#'                                          tools = selected_tool_names)
#'   print("Performance for CPC2, CPAT, FEELnc (rounded):")
#'   print(performance_stats_specific)
#'
#'   # --- Example 2: Simulate non-interactive selection ---
#'   cat("\nSimulating non-interactive run (will select first tool by default in helper):\n")
#'   performance_stats_noninteractive <- BestTool(SumSingleTools_list = example_summary_list,
#'                                                tools = NULL)
#'   print(performance_stats_noninteractive)
#'
#' } else {
#'   message("Please install 'caret' and ensure helper functions are loaded to run BestTool examples.")
#' }
#'
BestTool <- function(SumSingleTools_list, tools = NULL, digits = 4) {

  # --- 1. Input Validation ---
  # Call the generic helper with elements required by BestTool
  required_elements_for_besttool <- c("tools", "isNC")
  if (!.validate_input_list(SumSingleTools_list, required_elements_for_besttool)) {
    # Warnings are issued by the .validate_input_list helper
    return(NULL)
  }

  # Additional checks specific to BestTool (formerly in .validate_besttool_input)
  if (length(unique(SumSingleTools_list$isNC)) < 2) {
    warning("Reference labels ('isNC') in SumSingleTools_list do not contain both classes (0 and 1). Cannot calculate confusion matrix.", call. = FALSE)
    return(FALSE) # Indicate validation failure
  }
  if (!requireNamespace("caret", quietly = TRUE)) {
    warning("Package 'caret' is required for BestTool but not installed. Please install it.", call. = FALSE)
    return(NULL)
  }

  available_tools <- names(SumSingleTools_list$tools)
  reference_labels <- SumSingleTools_list$isNC

  # Double check after generic validation that tools list is not empty and has names
  if (is.null(available_tools) && length(SumSingleTools_list$tools) > 0) {
    warning("Tool names are missing from SumSingleTools_list$tools.", call. = FALSE)
    return(NULL)
  }
  if (length(available_tools) == 0 && length(SumSingleTools_list$tools) > 0) { # tools is list()
    warning("No tool predictions found in SumSingleTools_list$tools (empty list).", call. = FALSE)
    return(NULL)
  }


  # --- 2. Tool Selection ---
  if (is.null(tools)) {
    selected_tools <- .select_tools_interactively(available_tools)
  } else {
    selected_tools <- .validate_tool_names(tools, available_tools)
  }

  # Check if any tools remain after selection/validation
  if (is.null(selected_tools) || length(selected_tools) == 0) {
    warning("No valid tools selected or available for analysis. Returning NULL.", call. = FALSE)
    return(NULL)
  }

  # --- 3. Calculate Statistics for Selected Tools ---
  results_list <- list()
  # Prepare reference factor once
  ref_factor <- factor(reference_labels, levels = c("0", "1"))
  n_seqs <- length(ref_factor)

  for (tool_name in selected_tools) {
    tool_predictions <- SumSingleTools_list$tools[[tool_name]]

    # Additional check for individual tool prediction vector length
    if(length(tool_predictions) != n_seqs){
      warning(paste("Length mismatch for prediction vector of tool '", tool_name, "'. Expected ", n_seqs,
                    " but got ", length(tool_predictions), ". Skipping."), call. = FALSE)
      next # Skip to next tool
    }

    # Calculate stats using the helper function
    single_tool_stats_vector <- .calculate_single_tool_stats(tool_name, tool_predictions, ref_factor)

    if (!is.null(single_tool_stats_vector)) {
      results_list[[tool_name]] <- single_tool_stats_vector
    }
    # Warnings for failed calculations are handled within the helper
  }

  # --- 4. Format Output ---
  if (length(results_list) == 0) {
    warning("No statistics could be calculated for the selected tools.", call. = FALSE)
    return(NULL)
  }

  # --- Ensure Consistent Rows before cbind ---
  all_metric_names <- unique(unlist(lapply(results_list, names)))
  if (is.null(all_metric_names)) {
    warning("Could not determine metric names from results. Returning NULL.", call. = FALSE)
    return(NULL)
  }

  aligned_results_list <- lapply(results_list, function(tool_stats_vector) {
    template <- rep(NA_real_, length(all_metric_names))
    names(template) <- all_metric_names
    common_metrics <- intersect(names(tool_stats_vector), all_metric_names)
    if(length(common_metrics) > 0){
      template[common_metrics] <- tool_stats_vector[common_metrics]
    }
    data.frame(MetricValue = template, row.names = all_metric_names)
  })

  final_results_df <- do.call(cbind, aligned_results_list)
  colnames(final_results_df) <- names(aligned_results_list)

  final_results_df <- as.data.frame(lapply(final_results_df, function(col) {
    if(is.numeric(col)) round(col, digits = digits) else col
  }))
  rownames(final_results_df) <- all_metric_names

  return(final_results_df)
}
