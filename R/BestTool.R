#' Evaluate Performance of Coding Potential Tools
#'
#' Computes a comprehensive set of confusion matrix statistics (e.g., accuracy,
#' sensitivity, specificity) for individual coding potential prediction tools.
#' The function operates on summary data prepared by `summarizeTestSet`.
#'
#' @param summaryList A list generated by `summarizeTestSet()`, containing
#'   `$tools` (a list of 0/1 prediction vectors) and `$isNC` (a numeric vector
#'   of true labels: 1=nc, 0=cds).
#' @param tools An optional character vector specifying the names of the tools
#'   (from `names(summaryList$tools)`) to analyze. If `NULL`, the behavior
#'   depends on the session type: in an interactive session, the user will be
#'   prompted to select tools; in a non-interactive session, all available
#'   tools will be analyzed by default.
#' @param digits The number of decimal places to round the final statistics to
#'   (default: 4).
#'
#' @return A data frame where rows correspond to performance metrics and
#'   columns correspond to the selected tools. Returns `NULL` if the input is
#'   invalid or no statistics can be calculated.
#' @export
#'
#' @examples
#' # --- 1. Create a mock object mimicking the output of prepareEvaluationSets ---
#' # This object contains filtered data ready for evaluation.
#' set.seed(123)
#' n_seq <- 100
#' exampleEvaluationSummary <- list(
#'   tools = list(
#'     CPC2 = sample(c(0, 1), n_seq, replace = TRUE),
#'     CPAT = sample(c(0, 1), n_seq, replace = TRUE),
#'     PLEK = sample(c(0, 1), n_seq, replace = TRUE)
#'   ),
#'   isNC = sample(c(0, 1), n_seq, replace = TRUE) # True labels
#' )
#'
#' # --- 2. Run BestTool ---
#' # Example 1: Analyze a specific subset of tools
#' performance_stats <- BestTool(
#'   summaryList = exampleEvaluationSummary,
#'   tools = c("CPC2", "CPAT")
#' )
#' print(performance_stats)
#'
#' # Example 2: Analyze all available tools (non-interactively)
#' all_tools_stats <- BestTool(summaryList = exampleEvaluationSummary)
#' print(all_tools_stats)
#'
#' # --- 3. Interactive example (do not run in scripts) ---
#' if (interactive()) {
#'   # The following would prompt you to select tools from the console:
#'   # interactive_stats <- BestTool(summaryList = exampleSummaryList)
#' }
#'
BestTool <- function(summaryList, tools = NULL, digits = 4) {
  # --- 1. Input Validation ---
  stopifnot(
    "'summaryList' must be a list" = is.list(summaryList),
    "'summaryList' must contain 'tools' and 'isNC'" =
      all(c("tools", "isNC") %in% names(summaryList)),
    "'summaryList$tools' must be a list" = is.list(summaryList$tools),
    "'summaryList$isNC' must be numeric" = is.numeric(summaryList$isNC)
  )

  if (length(unique(summaryList$isNC)) < 2) {
    warning("Reference labels ('isNC') must contain both classes (0 and 1).",
            call. = FALSE)
    return(NULL)
  }

  available_tools <- names(summaryList$tools)
  if (length(available_tools) == 0) {
    warning("No tool predictions found in 'summaryList$tools'.", call. = FALSE)
    return(NULL)
  }

  # --- 2. Tool Selection (using the central helper function) ---
  selected_tools <- handleToolSelection(
    availableTools = available_tools,
    selectedTools = tools
  )

  if (length(selected_tools) == 0) {
    return(NULL) # Helper already issued a warning
  }

  # --- 3. Calculate Statistics ---
  results_list <- lapply(selected_tools, function(tool_name) {
    predictions <- summaryList$tools[[tool_name]]
    reference <- summaryList$isNC

    if (length(predictions) != length(reference)) {
      warning("Length mismatch for tool '", tool_name, "'. Skipping.",
              call. = FALSE)
      return(NULL)
    }

    calculateMetrics(predictions = predictions, reference = reference)
  })
  names(results_list) <- selected_tools

  results_list <- Filter(Negate(is.null), results_list)

  if (length(results_list) == 0) {
    warning("No statistics could be calculated for the selected tools.",
            call. = FALSE)
    return(NULL)
  }

  # --- 4. Format Output ---
  final_df <- do.call(cbind, results_list)
  desired_order <- c("Accuracy", "Kappa", "AccuracyLower", "AccuracyUpper",
                     "AccuracyNull", "AccuracyPValue", "McnemarPValue",
                     "Sensitivity", "Specificity", "Pos Pred Value",
                     "Neg Pred Value", "Precision", "Recall", "F1",
                     "Prevalence", "Detection Rate", "Detection Prevalence",
                     "Balanced Accuracy")
  final_df <- final_df[intersect(desired_order, rownames(final_df)), , drop = FALSE]
  final_df <- round(final_df, digits = digits)

  return(as.data.frame(final_df))
}
