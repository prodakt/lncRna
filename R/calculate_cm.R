#' Calculate Confusion Matrices and Optionally Use Pre-calculated Metrics for Filtering
#'
#' This function calculates `confusionMatrix` objects for tool combination predictions
#' from the `SumCombTools_list`. It can optionally use a separate data frame of
#' pre-calculated metrics (`BestTool_comb_metrics_data`) to inform which combinations'
#' results are highlighted or returned based on a threshold.
#'
#' @param SumCombTools_list list. A list generated by `SumCombTools()`, containing
#'        `$tool_combinations` (a list of 0/1 prediction vectors for each combination)
#'        and `$isNC` (the true class labels).
#' @param BestTool_comb_metrics_data data.frame (optional). A data frame where rows are
#'        metric names and columns are tool combination names (typically the output of
#'        `BestTool.comb()`). If provided, `metric_to_extract` will be looked up here
#'        for threshold decisions. Defaults to `NULL`.
#' @param positive_class character. The class level to be considered the "positive" class
#'        (e.g., "1"). Defaults to "1".
#' @param print_metric_threshold_methods logical. If TRUE, prints performance metric values
#'        for each combination, indicating if it meets the `threshold`. Defaults to FALSE.
#' @param threshold numeric. A threshold (0 to 1) used to evaluate `metric_to_extract`.
#'        Defaults to 0.8.
#' @param return_only_high_methods logical. If TRUE, returns confusion matrices only for
#'        combinations meeting the `threshold`. Defaults to FALSE.
#' @param metric_to_extract character. The performance metric to extract/evaluate
#'        (e.g., "Accuracy", "Sensitivity"). Defaults to "Accuracy".
#'
#' @return list.
#' A named list of `confusionMatrix` objects (calculated from `SumCombTools_list`).
#' If `return_only_high_methods = TRUE`, the list is filtered based on the `metric_to_extract`
#' value (from `BestTool_comb_metrics_data` if available, otherwise from the new CM)
#' compared against the `threshold`.
#'
#' @examples
#'
#' if (requireNamespace("caret", quietly = TRUE) &&
#'     exists(".validate_input_list") && exists(".select_tools_interactively") &&
#'     exists(".validate_tool_names") && exists("SumCombTools") &&
#'     exists(".calculate_single_tool_stats") && exists("BestTool.comb")) {
#'
#'   # 1. Create example_sst_list (input for SumCombTools)
#'   set.seed(101)
#'   n_seq_ex <- 50
#'   example_sst_list <- list(
#'     seqIDs = paste0("Seq", 1:n_seq_ex),
#'     tools = list(
#'       ToolX = sample(c(0,1),n_seq_ex,replace=TRUE,prob=c(0.5,0.5)),
#'       ToolY = sample(c(0,1),n_seq_ex,replace=TRUE,prob=c(0.4,0.6)),
#'       ToolZ = sample(c(0,1),n_seq_ex,replace=TRUE,prob=c(0.7,0.3))
#'     ),
#'     type = sample(c("nc","cds"),n_seq_ex,replace=TRUE), isNC=NULL
#'   )
#'   example_sst_list$isNC <- ifelse(example_sst_list$type=="nc",1,0)
#'
#'   # 2. Generate SumCombTools_list_example
#'   SumCombTools_list_example <- SumCombTools(
#'       SumSingleTools_list = example_sst_list,
#'       tools = c("ToolX", "ToolY", "ToolZ")
#'   )
#'
#'   # 3. Generate BestTool_comb_metrics_example (simulating BestTool.comb output)
#'   BestTool_comb_metrics_example <- NULL
#'   if (!is.null(SumCombTools_list_example)) {
#'     BestTool_comb_metrics_example <- BestTool.comb(
#'       SumCombTools_list = SumCombTools_list_example
#'     )
#'   }
#'
#'   if (!is.null(SumCombTools_list_example)) {
#'     # Example 1: Using SumCombTools_list only
#'     cat("\nExample 1: Using SumCombTools_list only\n")
#'     cm_list1 <- calculate_cm(
#'       SumCombTools_list = SumCombTools_list_example,
#'       print_metric_threshold_methods = TRUE,
#'       metric_to_extract = "Accuracy"
#'     )
#'     # print(names(cm_list1))
#'
#'     # Example 2: Using both SumCombTools_list and BestTool_comb_metrics_example
#'     if(!is.null(BestTool_comb_metrics_example)){
#'       cat("\nExample 2: Using both lists, filtering by Sensitivity >= 0.5\n")
#'       cm_list2 <- calculate_cm(
#'         SumCombTools_list = SumCombTools_list_example,
#'         BestTool_comb_metrics_data = BestTool_comb_metrics_example,
#'         return_only_high_methods = TRUE,
#'         metric_to_extract = "Sensitivity",
#'         threshold = 0.50,
#'         print_metric_threshold_methods = TRUE
#'       )
#'       # print(names(cm_list2))
#'     }
#'   } else {
#'     message("Example SumCombTools_list_example could not be generated.")
#'   }
#' } else {
#'   message("Please install 'caret', ensure SumCombTools, BestTool.comb and helpers are loaded.")
#' }
#' @importFrom caret confusionMatrix
#' @export
calculate_cm <- function(SumCombTools_list,
                         print_metric_threshold_methods = FALSE, threshold = 0.8, return_only_high_methods = FALSE,
                         metric_to_extract = "Accuracy", BestTool_comb_metrics_data = NULL, positive_class = "1") {

  # --- Input Validation (using a local helper) ---
  if (!.validate_calculate_cm_input(SumCombTools_list, BestTool_comb_metrics_data, threshold, metric_to_extract, positive_class)) {
    return(list()) # Return empty list on validation failure
  }

  # --- Initialize lists to store results ---
  confusion_matrix_list <- list() # Stores all calculated CMs for potential return
  high_metric_matrix_list <- list() # Stores CMs that meet the threshold

  # --- Get combination names and reference labels ---
  combination_names <- names(SumCombTools_list$tool_combinations)
  reference_labels <- SumCombTools_list$isNC
  n_seqs <- length(reference_labels)

  if (is.null(combination_names) || length(combination_names) == 0) {
    warning("No tool combinations found in SumCombTools_list$tool_combinations.", call. = FALSE)
    return(list())
  }

  cat("\n --- Confusion Matrix Calculation for Tool Combinations ---\n")

  # --- Loop through each combination ---
  for (selected_combination_name in combination_names) {
    predictions_vector <- SumCombTools_list$tool_combinations[[selected_combination_name]]

    if (length(predictions_vector) != n_seqs) {
      warning(paste("Length mismatch for prediction vector of combination '", selected_combination_name,
                    "'. Expected ", n_seqs, " but got ", length(predictions_vector), ". Skipping."), call. = FALSE)
      next
    }

    # Always calculate the confusion matrix from SumCombTools_list raw data
    current_cm <- .calculate_single_cm_for_calc_cm(
      predictions = predictions_vector,
      reference = reference_labels,
      positive_class = positive_class,
      combination_name = selected_combination_name
    )

    if (is.null(current_cm)) { # Skip if CM calculation failed for this combination
      next
    }

    # Store the calculated CM
    confusion_matrix_list[[selected_combination_name]] <- current_cm

    # Determine the metric value to use for decision-making
    metric_value_for_decision <- NA_real_

    if (!is.null(BestTool_comb_metrics_data)) {
      if (selected_combination_name %in% colnames(BestTool_comb_metrics_data) &&
          metric_to_extract %in% rownames(BestTool_comb_metrics_data)) {
        metric_value_for_decision <- BestTool_comb_metrics_data[metric_to_extract, selected_combination_name]
        # Ensure it's numeric
        if(!is.numeric(metric_value_for_decision)) metric_value_for_decision <- NA_real_
      } else {
        warning(paste("Metric '", metric_to_extract, "' for combination '", selected_combination_name,
                      "' not found in provided BestTool_comb_metrics_data. Will extract from new CM."), call. = FALSE)
      }
    }

    # If metric_value_for_decision is still NA (not found or BestTool_comb_metrics_data not provided),
    # extract it from the newly calculated current_cm.
    if (is.na(metric_value_for_decision)) {
      metric_value_for_decision <- .extract_metric_value_for_calc_cm(current_cm, metric_to_extract, selected_combination_name)
    }

    # Process printing based on metric_value_for_decision
    if (print_metric_threshold_methods) {
      output_string <- paste("Combination: '", selected_combination_name, "' - ", metric_to_extract, ": ",
                             if(is.na(metric_value_for_decision)) "NA" else sprintf("%.4f", metric_value_for_decision), sep="")
      if (!is.na(metric_value_for_decision) && metric_value_for_decision > threshold) {
        output_string <- paste(output_string, " -  *** HIGH ", toupper(metric_to_extract), " (>", threshold, ") ***", sep="")
      }
      cat(output_string, "\n")
    }

    # Decide whether to add the current_cm to high_metric_matrix_list
    if (!is.na(metric_value_for_decision) && metric_value_for_decision >= threshold) {
      high_metric_matrix_list[[selected_combination_name]] <- current_cm
    }
  }

  cat("\n--- End of Confusion Matrix Calculation for Tool Combinations ---\n")

  if (return_only_high_methods) {
    return(high_metric_matrix_list)
  } else {
    return(confusion_matrix_list) # Return all *calculated* CMs
  }
}

# --- Helper Functions for calculate_cm ---

#' Validate Input Data for calculate_cm
#'
#' @param SumCombTools_list list. Input from SumCombTools.
#' @param BestTool_comb_metrics_data data.frame or NULL. Pre-calculated metrics.
#' @param threshold numeric.
#' @param metric_to_extract character.
#' @param positive_class character.
#' @return logical. TRUE if valid, FALSE otherwise.
#' @noRd
.validate_calculate_cm_input <- function(SumCombTools_list, BestTool_comb_metrics_data, threshold, metric_to_extract, positive_class) {
  # Validate SumCombTools_list
  if (!is.list(SumCombTools_list) ||
      !all(c("tool_combinations", "isNC") %in% names(SumCombTools_list))) {
    stop("Input 'SumCombTools_list' must be a list containing 'tool_combinations' and 'isNC'.")
  }
  if (!is.list(SumCombTools_list$tool_combinations)) {
    warning("'$tool_combinations' element in SumCombTools_list must be a list.", call. = FALSE)
    return(FALSE)
  }
  if (length(SumCombTools_list$isNC) == 0) {
    warning("'$isNC' in SumCombTools_list is empty.", call. = FALSE)
    return(FALSE)
  }
  if (length(unique(SumCombTools_list$isNC)) < 2) {
    warning("Reference labels ('isNC') must contain at least two unique classes.", call. = FALSE)
    return(FALSE)
  }

  # Validate BestTool_comb_metrics_data if provided
  if (!is.null(BestTool_comb_metrics_data) && !is.data.frame(BestTool_comb_metrics_data)) {
    warning("'BestTool_comb_metrics_data' must be a data frame or NULL.", call. = FALSE)
    return(FALSE)
  }

  # Validate other parameters
  if (!is.numeric(threshold) || threshold < 0 || threshold > 1) {
    stop("'threshold' must be a numeric value between 0 and 1.")
  }
  if (!is.character(metric_to_extract) || length(metric_to_extract) != 1) {
    stop("'metric_to_extract' must be a single character string.")
  }
  if (!is.character(positive_class) || length(positive_class) != 1) {
    stop("'positive_class' must be a single character string.")
  }
  if (!requireNamespace("caret", quietly = TRUE)) {
    warning("Package 'caret' is required but not installed.", call. = FALSE)
    return(FALSE)
  }
  return(TRUE)
}

#' Calculate Single Confusion Matrix for calculate_cm
#'
#' @param predictions numeric vector. Predictions (0/1).
#' @param reference numeric vector. True labels (0/1).
#' @param positive_class character.
#' @param combination_name character. Name of the current combination (for error messages).
#' @return confusionMatrix object or NULL on error.
#' @noRd
.calculate_single_cm_for_calc_cm <- function(predictions, reference, positive_class, combination_name) {
  # Ensure "0" and "1" are the defined levels, in that order.
  # This addresses the user's request for the CM table display order.
  fixed_levels <- c("0", "1")

  # Convert predictions and reference to character to handle cases where they might be numeric 0/1
  # and to ensure factor levels are treated as characters initially.
  predictions_char <- as.character(predictions)
  reference_char <- as.character(reference)

  # Check if positive_class is present in the reference data
  if (!positive_class %in% unique(reference_char)) {
    warning(paste("Positive class '", positive_class, "' not found in reference labels for combination '",
                  combination_name, "'. Skipping confusion matrix calculation."), call. = FALSE)
    return(NULL)
  }
  # Check if positive_class is present in the prediction data
  if (!positive_class %in% unique(predictions_char)) {
    warning(paste("Positive class '", positive_class, "' not found in predicted labels for combination '",
                  combination_name, "'. Metrics might be affected (e.g., Precision/Recall could be NA/NaN)."), call. = FALSE)
  }
  # Check if all values in predictions and reference are covered by fixed_levels
  # This is a sanity check. If data has other values, factor() will introduce NAs.
  all_data_values <- unique(c(predictions_char, reference_char))
  if(!all(all_data_values %in% fixed_levels)){
    warning(paste("Data for combination '", combination_name,
                  "' contains values other than '0' or '1'. Ensure predictions and reference are binary (0/1)."),
            call. = FALSE)
    # Depending on desired strictness, could return NULL here.
    # For now, allow factor() to handle it, which will coerce non-matching values to NA.
  }


  data_factor <- factor(predictions_char, levels = fixed_levels)
  reference_factor <- factor(reference_char, levels = fixed_levels)

  cm <- tryCatch({
    caret::confusionMatrix(
      data = data_factor,
      reference = reference_factor,
      positive = positive_class # positive_class must be one of the levels in fixd_levels
    )
  }, error = function(e) {
    warning(paste("Error calculating confusionMatrix for combination '", combination_name, "': ", e$message), call. = FALSE)
    return(NULL)
  })
  return(cm)
}

#' Print Metric Information for a Combination
#'
#' This helper function is responsible for printing the specified performance metric
#' for a given tool combination. If `print_metric_threshold_methods` is TRUE,
#' it also indicates if the metric meets or exceeds a given threshold.
#' This function is called for its side effect (printing to the console).
#'
#' @param selected_combination_name character. The name of the tool combination being processed.
#' @param metric_to_extract character. The name of the performance metric being reported
#'        (e.g., "Accuracy", "Sensitivity").
#' @param metric_value numeric. The actual calculated value of the `metric_to_extract`
#'        for the `selected_combination_name`. Can be `NA`.
#' @param print_metric_threshold_methods logical. If TRUE, prints the metric value and
#'        indicates if it's above the `threshold`.
#' @param threshold numeric. The threshold to compare the `metric_value` against.
#'
#' @return Invisible NULL. This function is used for its side effect of printing.
#' @noRd
#' @keywords internal print helper metric
#'
.process_metric_and_print_for_calc_cm <- function(selected_combination_name,
                                                  metric_to_extract,
                                                  metric_value,
                                                  print_metric_threshold_methods,
                                                  threshold) {

  # Only proceed with printing if print_metric_threshold_methods is TRUE
  if (print_metric_threshold_methods) {
    # Construct the base output string
    output_string <- paste("Combination: '", selected_combination_name, "' - ",
                           metric_to_extract, ": ",
                           # Format the metric value, handling NA
                           if(is.na(metric_value)) "NA" else sprintf("%.4f", metric_value),
                           sep="")

    # If the metric value is not NA and exceeds the threshold, append high metric indicator
    if (!is.na(metric_value) && metric_value > threshold) {
      output_string <- paste(output_string, " -  *** HIGH ", toupper(metric_to_extract),
                             " (>", threshold, ") ***", sep="")
    }
    # Print the constructed string to the console
    cat(output_string, "\n")
  }

  # Return NULL invisibly as the function is used for its side effects
  invisible(NULL)
}



#' Extract Metric Value for calculate_cm
#'
#' @param confusion_matrix_obj confusionMatrix.
#' @param metric_name character.
#' @param combination_name character. Name of the combination (for error messages).
#' @return numeric. Metric value or NA.
#' @noRd
.extract_metric_value_for_calc_cm <- function(confusion_matrix_obj, metric_name, combination_name) {
  metric_value <- NA_real_

  if (metric_name %in% names(confusion_matrix_obj$overall)) {
    metric_value <- confusion_matrix_obj$overall[[metric_name]]
  } else if (metric_name %in% names(confusion_matrix_obj$byClass)) {
    metric_value <- confusion_matrix_obj$byClass[[metric_name]]
  } else {
    warning(paste("Metric '", metric_name, "' not found in confusion matrix for combination '",
                  combination_name, "'. Available metrics: ",
                  paste(c(names(confusion_matrix_obj$overall), names(confusion_matrix_obj$byClass)), collapse=", "),
                  ". Please enter a correct metric name."), call. = FALSE)
  }
  if (is.character(metric_value) && metric_value == "NaN") return(NaN)
  if (!is.numeric(metric_value)) return(NA_real_)
  return(metric_value)
}
