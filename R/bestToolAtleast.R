#' Evaluate Performance of Agreement Thresholds
#'
#' Computes confusion matrix statistics for each "at least n" agreement
#' threshold generated by `evaluateToolsThresholds`.
#'
#' @param agreementSummary A list generated by `evaluateToolsThresholds()`,
#'   containing `$isNC` (true labels) and `$atLeastN` (a list of 0/1 prediction
#'   vectors named `atl1`, `atl2`, etc.).
#' @param digits The number of decimal places to round the final statistics to
#'   (default: 4).
#'
#' @return A data frame where rows are performance metrics and columns
#'   correspond to the "at least n" (`atl1`, `atl2`, ...) thresholds. Returns
#'   `NULL` if the input is invalid or no statistics can be calculated.
#' @export
#'
#' @examples
#' # --- 1. Create a mock object mimicking the output of prepareEvaluationSets ---
#' # This object serves as input for evaluating thresholds.
#' set.seed(789)
#' n_seq <- 100
#' # First, create the summary object (as if from prepareEvaluationSets)
#' evaluationSummary <- list(
#'   seqIDs = paste0("S", 1:n_seq),
#'   isNC = sample(c(0, 1), n_seq, replace = TRUE),
#'   type = sample(c("nc", "cds"), n_seq, replace = TRUE),
#'   tools = list(
#'     ToolA = sample(c(0, 1), n_seq, replace = TRUE),
#'     ToolB = sample(c(0, 1), n_seq, replace = TRUE),
#'     ToolC = sample(c(0, 1), n_seq, replace = TRUE)
#'   )
#' )
#'
#' # --- 2. Create the agreement summary using evaluateToolsThresholds ---
#' # This is the object that BestToolAtleast actually takes as input
#' agreementSummary <- evaluateToolsThresholds(summaryList = evaluationSummary)
#'
#' # --- 3. Run BestToolAtleast on the result ---
#' if (!is.null(agreementSummary)) {
#'   performance_thresholds <- BestToolAtleast(
#'     agreementSummary = agreementSummary
#'   )
#'   print(performance_thresholds)
#' }
#'
BestToolAtleast <- function(agreementSummary, digits = 4) {
    # --- 1. Input Validation ---
    stopifnot(
        "'agreementSummary' must be a list" = is.list(agreementSummary),
        "'agreementSummary' must contain 'isNC' and 'atLeastN'" =
            all(c("isNC", "atLeastN") %in% names(agreementSummary)),
        "'agreementSummary$atLeastN' must be a list" = 
            is.list(agreementSummary$atLeastN),
        "'agreementSummary$isNC' must be numeric" = 
            is.numeric(agreementSummary$isNC)
    )
    
    at_least_n_predictions <- agreementSummary$atLeastN
    if (length(at_least_n_predictions) == 0) {
        warning("Input list element '$atLeastN' is empty.", call. = FALSE)
        return(NULL)
    }
    
    reference_labels <- agreementSummary$isNC
    if (length(unique(reference_labels)) < 2) {
        warning("Reference labels ('isNC') must contain both classes (0 and 1).",
                call. = FALSE)
        return(NULL)
    }
    
    # --- 2. Calculate Statistics for each 'atl{n}' vector ---
    results_list <- lapply(names(at_least_n_predictions), function(atl_name) {
        predictions_vector <- at_least_n_predictions[[atl_name]]
        
        if (length(predictions_vector) != length(reference_labels)) {
            warning("Length mismatch for prediction vector '", atl_name,
                          "'. Skipping.", call. = FALSE)
            return(NULL)
        }
        
        calculateMetrics(predictions = predictions_vector, 
                         reference = reference_labels)
    })
    names(results_list) <- names(at_least_n_predictions)
    
    results_list <- Filter(Negate(is.null), results_list)
    
    if (length(results_list) == 0) {
        warning("No statistics could be calculated for any threshold.", call. = FALSE)
        return(NULL)
    }
    
    # --- 3. Format Output ---
    final_df <- do.call(cbind, results_list)
    
    desired_order <- c("Accuracy", "Kappa", "AccuracyLower", "AccuracyUpper", 
                       "AccuracyNull", "AccuracyPValue", "McnemarPValue", 
                       "Sensitivity", "Specificity", "Pos Pred Value", 
                       "Neg Pred Value", "Precision", "Recall", "F1", 
                       "Prevalence", "Detection Rate", "Detection Prevalence", 
                       "Balanced Accuracy")
    final_df <- final_df[intersect(desired_order, rownames(final_df)), , drop = FALSE]
    
    final_df <- round(final_df, digits = digits)
    
    return(as.data.frame(final_df))
}